{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Algorithm_selecion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqPn8myiuXMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b6e9548-726c-4268-f92e-9f3a304649a5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# ======= < Basic imports > ==============\n",
        "import nltk\n",
        "import nltk.classify.util\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import unicodedata\n",
        "import sklearn.datasets,sys,re,timeit\n",
        "import json\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "import warnings\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from tokenize import tokenize, untokenize, NUMBER, STRING, NAME, OP\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.gridspec as gridspec\n",
        "import itertools\n",
        "import sqlite3\n",
        "import time\n",
        "import sys\n",
        "import gensim\n",
        "import random\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "\n",
        "# =========== < End > ===================\n",
        "\n",
        "#========= Classifiers ===========================================\n",
        "from nltk.corpus import names\n",
        "from sklearn import model_selection\n",
        "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble  import GradientBoostingClassifier, RandomForestClassifier,VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,ExtraTreesClassifier,BaggingClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.preprocessing import FunctionTransformer,StandardScaler,LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest,SelectFromModel,f_regression\n",
        "from sklearn.pipeline import Pipeline,FeatureUnion\n",
        "from sklearn.linear_model import Ridge,Lasso,RidgeClassifier,SGDClassifier\n",
        "from sklearn.utils import shuffle\n",
        "from mlxtend.classifier import EnsembleVoteClassifier\n",
        "from itertools import combinations\n",
        "#from mlens.ensemble import SuperLearner\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models import FastText  \n",
        "#from glove import Corpus, Glove\n",
        "# =========== < End > ===================\n",
        "\n",
        "#========== <Count Vectorization,feature extraction and summaries > ======================\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,TfidfTransformer\n",
        "from sklearn.model_selection import  train_test_split,cross_val_score,GridSearchCV\n",
        "from sklearn.metrics import make_scorer, f1_score, accuracy_score, recall_score, precision_score, classification_report, precision_recall_fscore_support\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix,mean_squared_error,mean_absolute_error\n",
        "# =========== < End > ===================\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Conv1D, Dropout, Dense, Flatten, LSTM, MaxPooling1D, Bidirectional,Activation, Input, Embedding,GRU\n",
        "from keras.optimizers import Adam,RMSprop\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "from gensim.test.utils import common_texts, get_tmpfile\n",
        "from gensim.models import word2vec,FastText \n",
        "from sklearn.preprocessing import scale\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tqdm import tqdm\n",
        "from collections import Counter"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gi7hqBX8gOh"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BskUGhChvA5d"
      },
      "source": [
        "def Remove_HTML_Elements_For_Df(inputlistDf):\n",
        "        try:\n",
        "            for i in range(len(inputlistDf)):\n",
        "                current_comment= inputlistDf['Comments1'].values[i]\n",
        "                inputlistDf['Comments1'].values[i] =BeautifulSoup(current_comment,\"html.parser\").get_text()\n",
        "            \n",
        "            return inputlistDf\n",
        "\n",
        "        except Exception as e:        \n",
        "                  e = sys.exc_info()[1]\n",
        "                  full_Error=\"Remove_HTML_Elements_For_Df: \"+str(e)+\"\\n\"\n",
        "                  raise Exception(full_Error)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_39-4BQvwMMk"
      },
      "source": [
        " def Remove_NonWord_Entries_For_Df(input_Df):\n",
        "          try:\n",
        "\n",
        "              non_Word_Entry_List=[]\n",
        "              #Remove non words\n",
        "              for i in range(len(input_Df)):\n",
        "                  current_comment= input_Df['Comments1'].values[i]     \n",
        "\n",
        "                  #Then append back after checking for numerical values\n",
        "                  input_Df['Comments1'].values[i]=(' '.join([word for word in current_comment.split() if word.isdigit()==False]))       \n",
        "\n",
        "              return input_Df     \n",
        "\n",
        "          except Exception as e:\n",
        "                    e = sys.exc_info()[1]\n",
        "                    full_Error=\"Remove_NonWord_Entries_For_Df: \"+str(e)+\"\\n\"\n",
        "                    raise Exception(full_Error)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcQPNSJgwbwc"
      },
      "source": [
        "def Remove_Special_Characters_For_List(input_comment,pronouns_List):\n",
        "        try:\n",
        "            regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "            cleaned_List = []\n",
        "           \n",
        "            for current_comment in input_comment:\n",
        "                tokenized_List = []\n",
        "                punctuation_Splitted_List=[]\n",
        "                punctuation_Removed_String = \"\"\n",
        "                for split_comment in current_comment.split():\n",
        "                    split_comment = re.sub('\\@\\w+', '', split_comment)\n",
        "                    split_comment = re.sub('\\#\\w+','', split_comment)\n",
        "                    split_comment = re.sub('\\#','',split_comment)\n",
        "                    split_comment = re.sub('RT','',split_comment)\n",
        "                    split_comment = re.sub('&amp;','',split_comment)\n",
        "                    split_comment = re.sub('[0-9]+','',split_comment)\n",
        "                    split_comment = re.sub('//t.co/\\w+','',split_comment)\n",
        "                    split_comment = re.sub('w//','',split_comment)\n",
        "                    split_comment = split_comment.lower()\n",
        "                    tokenized_List.append(split_comment.split())   \n",
        "                    \n",
        "                for tokenized_Elem in tokenized_List:\n",
        "                    punctuation_Removed_Elem=regex.sub('', str(tokenized_Elem))\n",
        "                    punctuation_Splitted_List.append(punctuation_Removed_Elem)\n",
        "                    \n",
        "                                       \n",
        "                for elem in punctuation_Splitted_List:         \n",
        "                    if  elem not in pronouns_List:\n",
        "                        punctuation_Removed_String+=(\" \"+elem)\n",
        "                        \n",
        "                        \n",
        "                cleaned_List.append(punctuation_Removed_String) \n",
        "                \n",
        "            return cleaned_List\n",
        "\n",
        "        except Exception as e:        \n",
        "            e = sys.exc_info()[1]\n",
        "            full_Error=\"Remove_Special_Characters_For_List: \"+str(e)+\"\\n\"\n",
        "            raise Exception(full_Error)\n",
        "            #return full_Error\n",
        "            \n",
        "def Remove_Special_Characters_For_Df(inputlistDf,pronouns_List):\n",
        "        try:\n",
        "            regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "            cleaned_List = []\n",
        "           \n",
        "            for i in range(len(inputlistDf)):\n",
        "                current_comment= inputlistDf['Comments1'].values[i]\n",
        "                tokenized_List = []\n",
        "                punctuation_Splitted_List=[]\n",
        "                punctuation_Removed_String = \"\"\n",
        "                for split_comment in current_comment.split():\n",
        "                    split_comment = re.sub('\\@\\w+', '', split_comment)\n",
        "                    split_comment = re.sub('\\#\\w+','', split_comment)\n",
        "                    split_comment = re.sub('\\#','',split_comment)\n",
        "                    split_comment = re.sub('RT','',split_comment)\n",
        "                    split_comment = re.sub('&amp;','',split_comment)\n",
        "                    split_comment = re.sub('[0-9]+','',split_comment)\n",
        "                    split_comment = re.sub('//t.co/\\w+','',split_comment)\n",
        "                    split_comment = re.sub('w//','',split_comment)\n",
        "                    split_comment = split_comment.lower()\n",
        "                    tokenized_List.append(split_comment.split())   \n",
        "                    \n",
        "                for tokenized_Elem in tokenized_List:\n",
        "                    punctuation_Removed_Elem=regex.sub('', str(tokenized_Elem))\n",
        "                    punctuation_Splitted_List.append(punctuation_Removed_Elem)\n",
        "                    \n",
        "                                       \n",
        "                for elem in punctuation_Splitted_List:         \n",
        "                    if  elem not in pronouns_List:\n",
        "                        punctuation_Removed_String+=(\" \"+elem.lower())\n",
        "                        \n",
        "                        \n",
        "                inputlistDf['Comments1'].values[i]=punctuation_Removed_String\n",
        "                \n",
        "            return inputlistDf\n",
        "\n",
        "        except Exception as e:        \n",
        "            e = sys.exc_info()[1]\n",
        "            full_Error=\"Remove_Special_Characters_For_Df: \"+str(e)+\"\\n\"\n",
        "            raise Exception(full_Error)\n",
        "            #return full_Error"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg1bl9YhxxiT"
      },
      "source": [
        "#setting the data sets \n",
        "training_Data_Path='/content/drive/My Drive/Colab Notebooks/FYP/CommentsRefined.csv'\n",
        "pronouns_List='/content/drive/My Drive/Colab Notebooks/FYP/Pronouns.csv'\n",
        "training_Data_df= pd.read_csv(training_Data_Path,usecols=[0,1],header='infer',encoding='utf-8')  \n",
        "pronouns_df=pd.read_csv(pronouns_List,usecols=[0],header=None,encoding='utf-8')            \n",
        "pronouns_List=pronouns_df[0].values.tolist()\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_Q-9CHuyA9D"
      },
      "source": [
        "html_Cleaned_Training_Df=Remove_HTML_Elements_For_Df(training_Data_df)\n",
        "special_Symbol_Cleaned_Phrases_Df=Remove_Special_Characters_For_Df(html_Cleaned_Training_Df,pronouns_List)\n",
        "comment_Cleaned_NonWord_Df=Remove_NonWord_Entries_For_Df(special_Symbol_Cleaned_Phrases_Df)\n",
        "comment_Cleaned_NonWord_Df=comment_Cleaned_NonWord_Df.head(801)\n",
        "comment_Cleaned_NonWord_Df=shuffle(comment_Cleaned_NonWord_Df)\n",
        "#print(comment_Cleaned_NonWord_Df)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQaQFoBZrPO6"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(comment_Cleaned_NonWord_Df.Comments1,comment_Cleaned_NonWord_Df.isPositive,\n",
        "                                                 test_size=0.2,random_state=42,shuffle=True)\n",
        "\n",
        "no_Of_Folds=10\n",
        "tf_idf=TfidfVectorizer(sublinear_tf=True,min_df=3,norm='l2',encoding='utf-8',ngram_range=(1,3))\n",
        "train_featurs=tf_idf.fit_transform(X_train)\n",
        "test_featurs=tf_idf.transform(X_test)\n",
        "train_labls=Y_train\n",
        "test_labls=Y_test\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2rdauMdsMwQ"
      },
      "source": [
        "best_Parameter_List=[]\n",
        "prediction_Model_List=[    \n",
        "                   ('LinearSVC', LinearSVC(),{'C':[0.0001,0.001,0.01,0.1,1,10],'loss':['hinge','squared_hinge'],\n",
        "                                              'multi_class':['ovr','crammer_singer']}),\n",
        "                     \n",
        "                   ('MultinomialNB',MultinomialNB(),{'alpha':[0.0001,0.001,0.01,0.1,1,10]}),\n",
        "\n",
        "                   ('LogisticRegression',LogisticRegression(),{'C':[0.0001,0.001,0.01,0.1,1,10],\n",
        "                                                                'penalty' : ['l1', 'l2']}),\n",
        "    \n",
        "                   ('SVC',SVC(),{'C':[0.0001,0.001,0.01,0.1,1,10],'kernel' :['linear', 'rbf', 'poly'],\n",
        "                                  'gamma':[0.1, 1, 10, 100]}),\n",
        "    \n",
        "                   ('RidgeClassifier',RidgeClassifier(),{'alpha':[0.0001,0.001,0.01,0.1,1,10]}),\n",
        "    \n",
        "                   ('SGDClassifier',SGDClassifier(),{'alpha':[0.0001,0.001,0.01,0.1,1,10]}),\n",
        "    \n",
        "                   ('RandomForestClassifier',RandomForestClassifier(),{'n_estimators': [50,200,350,500,650,800],\n",
        "                                                                       'max_features': ['auto', 'sqrt', 'log2'],\n",
        "                                                                       'criterion':['gini','entropy']}),\n",
        "\n",
        "                   ('DecisionTreeClassifier',DecisionTreeClassifier(),{'min_samples_split' : range(10,500,20),\n",
        "                                                                       'max_depth': range(1,20,2),\n",
        "                                                                       'criterion':['gini','entropy']}),\n",
        "\n",
        "                   ('KNeighborsClassifier',KNeighborsClassifier(),{'n_neighbors':list(range(1, 31)),\n",
        "                                                                   'metric':['euclidean','manhattan','minkowski']}),\n",
        "\n",
        "                   ('AdaBoostClassifier',AdaBoostClassifier(),{'n_estimators': [1, 2, 4, 8, 16, 32, 64, 100, 200],\n",
        "                                                              'learning_rate': [1, 0.5, 0.25, 0.1, 0.05, 0.01],\n",
        "                                                              'algorithm':['SAMME','SAMME.R']}),\n",
        "\n",
        "                  ('ExtraTreesClassifier',ExtraTreesClassifier(),{'n_estimators': [50,200,350,500,650,800],\n",
        "                                                                   'max_features': ['auto', 'sqrt', 'log2'],\n",
        "                                                                   'criterion':['gini','entropy']})\n",
        "                  \n",
        "    \n",
        "                  ]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2qx0mHNsOax"
      },
      "source": [
        "for model_Name,model,hyperParameterSet in prediction_Model_List:\n",
        "    clsf=GridSearchCV(model,hyperParameterSet,cv=no_Of_Folds,scoring='precision')\n",
        "    clsf.fit(train_featurs,train_labls)   \n",
        "    best_Parameter_List.append({  'Classifiers -':model_Name,\n",
        "                                     'Best Parameters -':clsf.best_params_                              \n",
        "                                  })\n",
        "best_Parameter_List"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MOeW4xwQSn1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "ed22bbca-c4c1-4ac8-c8fc-d3e115e0c358"
      },
      "source": [
        "df = pd.DataFrame(best_Parameter_List)\n",
        "df"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifiers -</th>\n",
              "      <th>Best Parameters -</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>{'C': 1, 'loss': 'squared_hinge', 'multi_class...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>{'alpha': 0.0001}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SVC</td>\n",
              "      <td>{'C': 1, 'gamma': 100, 'kernel': 'rbf'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RidgeClassifier</td>\n",
              "      <td>{'alpha': 1}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SGDClassifier</td>\n",
              "      <td>{'alpha': 0.001}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>{'criterion': 'gini', 'max_features': 'sqrt', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 17, 'min_sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>{'metric': 'euclidean', 'n_neighbors': 2}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>{'algorithm': 'SAMME.R', 'learning_rate': 0.5,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ExtraTreesClassifier</td>\n",
              "      <td>{'criterion': 'gini', 'max_features': 'auto', ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Classifiers -                                  Best Parameters -\n",
              "0                LinearSVC  {'C': 1, 'loss': 'squared_hinge', 'multi_class...\n",
              "1            MultinomialNB                                  {'alpha': 0.0001}\n",
              "2       LogisticRegression                      {'C': 0.001, 'penalty': 'l2'}\n",
              "3                      SVC            {'C': 1, 'gamma': 100, 'kernel': 'rbf'}\n",
              "4          RidgeClassifier                                       {'alpha': 1}\n",
              "5            SGDClassifier                                   {'alpha': 0.001}\n",
              "6   RandomForestClassifier  {'criterion': 'gini', 'max_features': 'sqrt', ...\n",
              "7   DecisionTreeClassifier  {'criterion': 'gini', 'max_depth': 17, 'min_sa...\n",
              "8     KNeighborsClassifier          {'metric': 'euclidean', 'n_neighbors': 2}\n",
              "9       AdaBoostClassifier  {'algorithm': 'SAMME.R', 'learning_rate': 0.5,...\n",
              "10    ExtraTreesClassifier  {'criterion': 'gini', 'max_features': 'auto', ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2A7uGwk687g"
      },
      "source": [
        "def Get_Absolute_Mean_Error(Y_true, Y_pred): \n",
        "    Y_true, Y_pred = np.array(Y_true), np.array(Y_pred)\n",
        "    return round(mean_absolute_error(Y_true,Y_pred) * 100,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDkWILjr7BLM"
      },
      "source": [
        "def Get_Root_Mean_Square_Error(y_actual, y_predicted):\n",
        "    return round((np.sqrt(mean_squared_error(y_actual, y_predicted))*100),2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJEaYKaH7HeF"
      },
      "source": [
        "bench_mark_results=[]\n",
        "\n",
        "algorithmsList=[\n",
        "                    ('LinearSVC',LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
        "                     intercept_scaling=1, loss='hinge', max_iter=1000,\n",
        "                     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
        "                     verbose=0)),\n",
        "                    ('MultinomialNB',MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)),\n",
        "                    ('LogisticRegression',LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "                                      intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
        "                                      n_jobs=1, penalty='l1', random_state=0, solver='saga',\n",
        "                                      tol=0.0001, verbose=0, warm_start=False)),\n",
        "                    ('SVC',SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
        "                        decision_function_shape='ovr', degree=3, gamma=0.1, kernel='linear',\n",
        "                        max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
        "                        tol=0.001, verbose=False)),\n",
        "                    ('RidgeClassifier',RidgeClassifier(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True,\n",
        "                                    max_iter=None, tol=0.001, class_weight=None, solver='auto', random_state=None)),\n",
        "                    ('SGDClassifier',SGDClassifier(alpha=0.001)),\n",
        "                    ('RandomForestClassifier',RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
        "                                            max_depth=3, max_features='sqrt', max_leaf_nodes=None,\n",
        "                                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                                            min_samples_leaf=1, min_samples_split=2,\n",
        "                                            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
        "                                            oob_score=False, random_state=0, verbose=0, warm_start=False)),          \n",
        "                    ('DecisionTreeClassifier',DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
        "                                            max_depth=3, max_features=None, max_leaf_nodes=None,\n",
        "                                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                                            min_samples_leaf=1, min_samples_split=10,\n",
        "                                            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
        "                                            splitter='best')),   \n",
        "                    ('KNeighborsClassifier',KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
        "                                       metric_params=None, n_jobs=1, n_neighbors=26, p=2,\n",
        "                                       weights='uniform')),\n",
        "                    ('AdaBoostClassifier',AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
        "                                      learning_rate=0.05, n_estimators=16, random_state=None)),                    \n",
        "                   ('ExtraTreesClassifier',ExtraTreesClassifier(n_estimators=500,max_features='sqrt',criterion='entropy'))\n",
        "                  \n",
        "               ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hse0-kNF7KU8"
      },
      "source": [
        "for model_Name,modelElem in algorithmsList:    \n",
        "    startTime = time.time()\n",
        "    modelElem.fit(train_featurs,train_labls)    \n",
        "    cross_val_score_train=cross_val_score(modelElem, train_featurs , train_labls, cv=no_Of_Folds)  \n",
        "    score_train=cross_val_score_train.mean()\n",
        "    yPredicted_train = modelElem.predict(train_featurs)\n",
        "    precision_train,recall_train,fscore_train,support_train=score(train_labls,yPredicted_train,average='macro')   \n",
        "    cross_val_score_test=cross_val_score(modelElem, test_featurs , test_labls, cv=no_Of_Folds)  \n",
        "    score_test=cross_val_score_test.mean()\n",
        "    yPredicted_test = modelElem.predict(test_featurs)\n",
        "    precision_test,recall_test,fscore_test,support_test=score(test_labls,yPredicted_test,average='macro')\n",
        "\n",
        "    endTime = time.time()\n",
        "    elapsedTime=endTime-startTime\n",
        "\n",
        "    bench_mark_results.append({  'Classifiers':model_Name,\n",
        "                                 'Precision[Training](%)':str(round(precision_train,2)*100),\n",
        "                                 #'Cross Validation Precision[Training](%)':str(round(score_train,2)*100),\n",
        "                                 'Precision[Test](%)':str(round(precision_test,2)*100),\n",
        "                                 #'Cross Validation Precision[Test](%)':str(round(score_test,2)*100),\n",
        "                                 #'CV Precision_Difference(%)':str((round((round(score_train,2)-round(score_test,2)),2)*100)),   \n",
        "                                 'Precision_Difference(%)':str((round((round(precision_train,2)-round(precision_test,2)),2)*100)),\n",
        "                                 'Mean Absolute Error[Training](%)':Get_Absolute_Mean_Error(train_labls,yPredicted_train),\n",
        "                                 'Mean Absolute Error[Test](%)':Get_Absolute_Mean_Error(test_labls,yPredicted_test),\n",
        "                                 'Root Mean Square Error[Training](%)':Get_Root_Mean_Square_Error(train_labls,yPredicted_train),\n",
        "                                 'Root Mean Square Error[Test](%)':Get_Root_Mean_Square_Error(test_labls,yPredicted_test),\n",
        "                                 'F1-Score[Train](%)':str(round(fscore_train,2)*100),\n",
        "                                 'F1-Score[Test](%)':str(round(fscore_test,2)*100),\n",
        "                                 'Recall[Train](%)':str(round(recall_train,2)*100),\n",
        "                                 'Recall[Test](%)':str(round(recall_test,2)*100),\n",
        "                                 'Elapsed_Time(Sec.)':str(round(elapsedTime,2))})\n",
        "    #print(len(bench_mark_results))\n",
        "    #print((bench_mark_results))\n",
        "bench_mark_results\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "dnKkqa_zVgUG",
        "outputId": "f158b591-8807-4881-dc93-927dceb6591e"
      },
      "source": [
        "df = pd.DataFrame(bench_mark_results)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Precision[Training](%)</th>\n",
              "      <th>Precision[Test](%)</th>\n",
              "      <th>Precision_Difference(%)</th>\n",
              "      <th>Mean Absolute Error[Training](%)</th>\n",
              "      <th>Mean Absolute Error[Test](%)</th>\n",
              "      <th>Root Mean Square Error[Training](%)</th>\n",
              "      <th>Root Mean Square Error[Test](%)</th>\n",
              "      <th>F1-Score[Train](%)</th>\n",
              "      <th>F1-Score[Test](%)</th>\n",
              "      <th>Recall[Train](%)</th>\n",
              "      <th>Recall[Test](%)</th>\n",
              "      <th>Elapsed_Time(Sec.)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>99.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.94</td>\n",
              "      <td>5.62</td>\n",
              "      <td>9.68</td>\n",
              "      <td>23.72</td>\n",
              "      <td>99.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>95.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.69</td>\n",
              "      <td>10.00</td>\n",
              "      <td>21.65</td>\n",
              "      <td>31.62</td>\n",
              "      <td>95.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>96.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.06</td>\n",
              "      <td>6.88</td>\n",
              "      <td>20.16</td>\n",
              "      <td>26.22</td>\n",
              "      <td>96.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>0.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SVC</td>\n",
              "      <td>99.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.94</td>\n",
              "      <td>5.62</td>\n",
              "      <td>9.68</td>\n",
              "      <td>23.72</td>\n",
              "      <td>99.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RidgeClassifier</td>\n",
              "      <td>99.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.78</td>\n",
              "      <td>6.25</td>\n",
              "      <td>8.84</td>\n",
              "      <td>25.00</td>\n",
              "      <td>99.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SGDClassifier</td>\n",
              "      <td>99.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.78</td>\n",
              "      <td>5.00</td>\n",
              "      <td>8.84</td>\n",
              "      <td>22.36</td>\n",
              "      <td>99.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>95.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.16</td>\n",
              "      <td>11.25</td>\n",
              "      <td>22.71</td>\n",
              "      <td>33.54</td>\n",
              "      <td>95.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>6.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>85.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.00</td>\n",
              "      <td>21.88</td>\n",
              "      <td>44.72</td>\n",
              "      <td>46.77</td>\n",
              "      <td>79.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>79.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>34.69</td>\n",
              "      <td>35.62</td>\n",
              "      <td>58.90</td>\n",
              "      <td>59.69</td>\n",
              "      <td>61.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>80.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>25.78</td>\n",
              "      <td>29.38</td>\n",
              "      <td>50.78</td>\n",
              "      <td>54.20</td>\n",
              "      <td>73.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>1.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ExtraTreesClassifier</td>\n",
              "      <td>100.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>20.92</td>\n",
              "      <td>100.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>19.56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Classifier  ... Elapsed_Time(Sec.)\n",
              "0                LinearSVC  ...               0.08\n",
              "1            MultinomialNB  ...               0.05\n",
              "2       LogisticRegression  ...               0.67\n",
              "3                      SVC  ...               0.31\n",
              "4          RidgeClassifier  ...               0.15\n",
              "5            SGDClassifier  ...               0.07\n",
              "6   RandomForestClassifier  ...                6.7\n",
              "7   DecisionTreeClassifier  ...               0.12\n",
              "8     KNeighborsClassifier  ...               0.25\n",
              "9       AdaBoostClassifier  ...               1.15\n",
              "10    ExtraTreesClassifier  ...              19.56\n",
              "\n",
              "[11 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLaH5XbGu9Wl"
      },
      "source": [
        "LabeledSentence = gensim.models.doc2vec.LabeledSentence\n",
        "tokenizer = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "\n",
        "def LabelizePhrases(phrases, label_type):\n",
        "    labelized = []\n",
        "    for i,v in tqdm(enumerate(phrases)):\n",
        "        label = '%s_%s'%(label_type,i)\n",
        "        labelized.append(LabeledSentence(v, [label]))\n",
        "    return labelized\n",
        "\n",
        "x_train = LabelizePhrases(list(X_train), 'TRAIN')\n",
        "x_test = LabelizePhrases(list(X_test), 'TEST')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbsOkvAexfz8"
      },
      "source": [
        "sizeList=[]\n",
        "bench_mark_results=[]\n",
        "sizeList=[100,150,200,250,300,350,400,450,500,550,600,650,700,750,800]\n",
        "n_dim=200\n",
        "min_count=3\n",
        "window=5\n",
        "workers=4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkLV6VZhxpLc"
      },
      "source": [
        "for sizeElem in sizeList:\n",
        "    startTime = time.time()\n",
        "\n",
        "    phrase_w2v = Word2Vec(size=sizeElem, min_count=3,window=5,workers=4)\n",
        "    phrase_w2v.build_vocab([x.words.split() for x in x_train])\n",
        "    phrase_w2v.train([x.words.split() for x in x_train],\n",
        "                           total_examples=phrase_w2v.corpus_count,\n",
        "                            epochs=phrase_w2v.epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzKcjuEzyPPs"
      },
      "source": [
        "    #building tf-idf matrix \n",
        "    vectorizer = TfidfVectorizer(analyzer=lambda x: x,sublinear_tf=True,min_df=3,norm='l2',encoding='utf-8',ngram_range=(1,3)) \n",
        "    matrix = vectorizer.fit_transform([x.words for x in x_train])\n",
        "    tf_idf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
        "    \n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxFMIUx0ZLzk"
      },
      "source": [
        "def BuildWordVector(tokens, size):\n",
        "    vec = np.zeros(size).reshape((1, size))\n",
        "    count = 0.\n",
        "    for word in tokens:\n",
        "        try:\n",
        "            vec += phrase_w2v[word].reshape((1, size)) * tf_idf[word]\n",
        "            count += 1.\n",
        "        except KeyError: # handling the case where the token is not\n",
        "                         # in the corpus. useful for testing.\n",
        "            continue\n",
        "    if count != 0:\n",
        "        vec /= count\n",
        "    return vec"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onM4vfCbzjed"
      },
      "source": [
        "    train_vecs_w2v = np.concatenate([BuildWordVector(z, sizeElem) for z in tqdm(map(lambda x: x.words, x_train))])\n",
        "    train_vecs_w2v = scale(train_vecs_w2v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzh7frPl_mFI"
      },
      "source": [
        "    test_vecs_w2v = np.concatenate([BuildWordVector(z, sizeElem) for z in tqdm(map(lambda x: x.words, x_test))])\n",
        "    test_vecs_w2v = scale(test_vecs_w2v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o7HVzo9_suo"
      },
      "source": [
        "    model = Sequential()\n",
        "    model.add(Dense(32, activation='relu', input_dim=sizeElem))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='mean_absolute_error',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_vecs_w2v, Y_train, epochs=15, batch_size=32, verbose=2)\n",
        "    score_train = model.evaluate(train_vecs_w2v, Y_train, batch_size=128, verbose=2)\n",
        "    score_test = model.evaluate(test_vecs_w2v, Y_test, batch_size=128, verbose=2)\n",
        "    val_predict_train = (np.asarray(model.predict(train_vecs_w2v))).round()\n",
        "    val_predict_test = (np.asarray(model.predict(test_vecs_w2v))).round()\n",
        "    precision_train = precision_score(Y_train, val_predict_train)\n",
        "    precision_test = precision_score(Y_test, val_predict_test)\n",
        "    recall_train = recall_score(Y_train, val_predict_train)\n",
        "    recall_test = recall_score(Y_test, val_predict_test)\n",
        "    f1_score_train=f1_score(Y_train, val_predict_train)\n",
        "    f1_score_test=f1_score(Y_test, val_predict_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma33TY62_w-H"
      },
      "source": [
        "    endTime = time.time()\n",
        "    elapsedTime=endTime-startTime\n",
        "    \n",
        "    bench_mark_results.append({  'No.Of Dimensions':sizeElem,\n",
        "                                 'Precision[Training](%)':str(round(precision_train,2)*100),\n",
        "                                 'F1-Score[Training](%)':str(round(f1_score_train,2)*100),\n",
        "                                 'Recall[Training](%)':str(round(recall_train,2)*100),\n",
        "                                 'Mean Absolute Error[Training](%)':str(Get_Absolute_Mean_Error(Y_train, val_predict_train)),\n",
        "                                 'Precision[Test](%)':str(round(precision_test,2)*100),   \n",
        "                                 'F1-Score[Test](%)':str(round(f1_score_test,2)*100),\n",
        "                                 'Recall[Test](%)':str(round(recall_test,2)*100),\n",
        "                                 'Mean Absolute Error[Test](%)':str(Get_Absolute_Mean_Error(Y_test, val_predict_test)), \n",
        "                                 'Precision_Difference(%)':str((round(((precision_train-precision_test)*100),2))),\n",
        "                                 'Elapsed_Time(Sec.)':str(round(elapsedTime,2))})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "GTiRkz5wgX7D",
        "outputId": "ae207c87-7c53-431c-e29a-fa2babd2360b"
      },
      "source": [
        "bench_mark_results\n",
        "df = pd.DataFrame(bench_mark_results)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No.Of Dimensions</th>\n",
              "      <th>Precision[Training](%)</th>\n",
              "      <th>F1-Score[Training](%)</th>\n",
              "      <th>Recall[Training](%)</th>\n",
              "      <th>Mean Absolute Error[Training](%)</th>\n",
              "      <th>Precision[Test](%)</th>\n",
              "      <th>F1-Score[Test](%)</th>\n",
              "      <th>Recall[Test](%)</th>\n",
              "      <th>Mean Absolute Error[Test](%)</th>\n",
              "      <th>Precision_Difference(%)</th>\n",
              "      <th>Elapsed_Time(Sec.)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>800</td>\n",
              "      <td>52.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>49.53</td>\n",
              "      <td>39.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>47.5</td>\n",
              "      <td>12.76</td>\n",
              "      <td>1871.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>800</td>\n",
              "      <td>52.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>49.53</td>\n",
              "      <td>39.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>47.5</td>\n",
              "      <td>12.76</td>\n",
              "      <td>1882.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>800</td>\n",
              "      <td>52.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>49.53</td>\n",
              "      <td>39.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>47.5</td>\n",
              "      <td>12.76</td>\n",
              "      <td>2016.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>800</td>\n",
              "      <td>52.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>49.53</td>\n",
              "      <td>39.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>47.5</td>\n",
              "      <td>12.76</td>\n",
              "      <td>2039.08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   No.Of Dimensions  ... Elapsed_Time(Sec.)\n",
              "0               800  ...            1871.81\n",
              "1               800  ...            1882.41\n",
              "2               800  ...            2016.84\n",
              "3               800  ...            2039.08\n",
              "\n",
              "[4 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM3wDppqQrRP"
      },
      "source": [
        "comment_Cleaned_NonWord_Df=comment_Cleaned_NonWord_Df.head(801)\n",
        "pos_Comments=comment_Cleaned_NonWord_Df.loc[comment_Cleaned_NonWord_Df['isPositive'] == 1]\n",
        "pos_Comments_List = list(pos_Comments['Comments1'])\n",
        "neg_Comments=comment_Cleaned_NonWord_Df.loc[comment_Cleaned_NonWord_Df['isPositive'] == 0]\n",
        "neg_Comments_List = list(neg_Comments['Comments1'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP4EMyu-Rv7f"
      },
      "source": [
        "max_no_tokens = 15\n",
        "comments_clean = list(comment_Cleaned_NonWord_Df['Comments1'])[:801]\n",
        "random.shuffle(comments_clean)\n",
        "train_size = int(0.8*(len(comments_clean)))\n",
        "test_size = int(0.2*(len(comments_clean)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcRWtt9NSblL",
        "outputId": "4fa95e28-5305-4c3d-cd31-e69151fb9c7a"
      },
      "source": [
        "print('Generating Labels ...')\n",
        "labels = []\n",
        "model_Name='FastText.model'\n",
        "with tqdm(total=len(comments_clean)) as pbar:\n",
        "    for Comments1 in comments_clean:\n",
        "        if Comments1 in neg_Comments:\n",
        "              labels.append(1)\n",
        "        else:\n",
        "              labels.append(0)\n",
        "\n",
        "        pbar.update(1)\n",
        "    word2vec_model = model_Name\n",
        "\n",
        "print('Generating FastText Vectors ...')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|| 800/800 [00:00<00:00, 176723.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generating Labels ...\n",
            "Generating FastText Vectors ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq17LNurSwPG"
      },
      "source": [
        "n_dim=100\n",
        "n_dim_array=[100,150,200,250,300,350,400,450,500,550,600,650,700,800]\n",
        "min_count_array=[3,9,12,15,18,21,24]\n",
        "window_arr=[5,10,15,20,25,30,35,40,45,50]\n",
        "window = 5\n",
        "benchmark_values_arr=[]\n",
        "min_count_elem=3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xuxl8wPlS1J-"
      },
      "source": [
        "for dim in n_dim_array:\n",
        "    \n",
        "    startTime = time.time()\n",
        "\n",
        "    #vector_size = 512   \n",
        "    model =phrase_w2v = FastText(sentences=comments_clean, size=dim, window=window,min_count=min_count_elem,workers=4)  #Word2Vec(sentences=phrases_clean, size=vector_size, window=window, negative=20, iter=50, workers=4)\n",
        "\n",
        "    #print('Word2Vec Created in {} seconds.'.format(time.time() - start))\n",
        "\n",
        "    model.save(word2vec_model)\n",
        "    #print('Word2Vec Model saved at {}'.format(word2vec_model))\n",
        "\n",
        "    model = Word2Vec.load(word2vec_model)\n",
        "\n",
        "    x_vectors = model.wv      \n",
        "\n",
        "    indexes = set(np.random.choice(len(comments_clean), train_size + test_size, replace=False))\n",
        "\n",
        "    x_train = np.zeros((train_size, max_no_tokens, dim), dtype=K.floatx())\n",
        "    y_train = np.zeros((train_size, 2), dtype=np.int32)\n",
        "\n",
        "    x_test = np.zeros((test_size, max_no_tokens, dim), dtype=K.floatx())\n",
        "    y_test = np.zeros((test_size, 2), dtype=np.int32)\n",
        "    \n",
        "   \n",
        "    for i, index in enumerate(indexes):\n",
        "        for t, token in enumerate(comments_clean[index]):\n",
        "            if t >= max_no_tokens:\n",
        "                break\n",
        "\n",
        "            if token not in x_vectors:\n",
        "                continue\n",
        "\n",
        "            if i < train_size:\n",
        "                x_train[i, t, :] = x_vectors[token]\n",
        "            else:\n",
        "                x_test[i - train_size, t, :] = x_vectors[token]\n",
        "\n",
        "\n",
        "        if i < train_size:\n",
        "            y_train[i, :] = [1.0, 0.0] if labels[index] == 0 else [0.0, 1.0]\n",
        "        else:\n",
        "            y_test[i - train_size, :] = [1.0, 0.0] if labels[index] == 0 else [0.0, 1.0]\n",
        "\n",
        "    #del comments_clean\n",
        "    #del labels\n",
        "\n",
        "    batch_size = 500\n",
        "    no_epochs = 5\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same',\n",
        "                     input_shape=(max_no_tokens, dim)))\n",
        "    model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same'))\n",
        "    model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
        "    model.add(MaxPooling1D(pool_size=3))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(512, dropout=0.2, recurrent_dropout=0.3)))\n",
        "\n",
        "    model.add(Dense(512, activation='sigmoid'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(512, activation='sigmoid'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(512, activation='sigmoid'))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='mean_absolute_error', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n",
        "\n",
        "    #print(model.summary())\n",
        "\n",
        "    model.fit(x_train, y_train, batch_size=batch_size, shuffle=True, epochs=no_epochs,\n",
        "             validation_data=(x_test, y_test))\n",
        "\n",
        "    score_train=model.evaluate(x=x_train, y=y_train, batch_size=32, verbose=1)\n",
        "    score_test=model.evaluate(x=x_test, y=y_test, batch_size=32, verbose=1)\n",
        "    #print(model.evaluate(x=x_test, y=y_test, batch_size=32, verbose=1))\n",
        "    #print(model.evaluate(x=x_train, y=y_train, batch_size=32, verbose=1))\n",
        "    endTime = time.time()\n",
        "    elapsedTime=endTime-startTime\n",
        "    benchmark_values_arr.append({'No.Of Dimensions':dim,                                \n",
        "                                 'Precision[Training](%)':str(round(score_train[1],2)*100),\n",
        "                                 'Mean Absolute Error[Training](%)':str(round(score_train[0],2)*100),\n",
        "                                 'Precision[Test](%)':str(round(score_test[1],2)*100),   \n",
        "                                 'Mean Absolute Error[Test](%)':str(round(score_test[0],2)*100), \n",
        "                                 'Precision_Difference(%)':str((round((score_train[1]-score_test[1]),2)*100)),\n",
        "                                 'Elapsed_Time(Sec.)':str(round(elapsedTime,2))})\n",
        "    \n",
        "print(benchmark_values_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "GvyXhpvHjf0D",
        "outputId": "22ce201d-0a89-4a4f-8579-6aace2438519"
      },
      "source": [
        "df = pd.DataFrame(benchmark_values_arr)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No.Of Dimensions</th>\n",
              "      <th>Precision[Training](%)</th>\n",
              "      <th>Mean Absolute Error[Training](%)</th>\n",
              "      <th>Precision[Test](%)</th>\n",
              "      <th>Mean Absolute Error[Test](%)</th>\n",
              "      <th>Precision_Difference(%)</th>\n",
              "      <th>Elapsed_Time(Sec.)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>150</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>200</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>250</td>\n",
              "      <td>100.0</td>\n",
              "      <td>7.000000000000001</td>\n",
              "      <td>100.0</td>\n",
              "      <td>7.000000000000001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>300</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>350</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>450</td>\n",
              "      <td>100.0</td>\n",
              "      <td>14.000000000000002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>14.000000000000002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>500</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>550</td>\n",
              "      <td>100.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>600</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>650</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>700</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>800</td>\n",
              "      <td>100.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    No.Of Dimensions  ... Elapsed_Time(Sec.)\n",
              "0                100  ...              18.92\n",
              "1                150  ...              19.04\n",
              "2                200  ...              19.76\n",
              "3                250  ...              20.49\n",
              "4                300  ...              20.78\n",
              "5                350  ...              19.42\n",
              "6                400  ...              22.61\n",
              "7                450  ...              22.23\n",
              "8                500  ...              21.56\n",
              "9                550  ...               22.3\n",
              "10               600  ...              23.98\n",
              "11               650  ...              21.75\n",
              "12               700  ...              21.75\n",
              "13               800  ...              24.37\n",
              "\n",
              "[14 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "kBltSDL739nQ",
        "outputId": "b04df8af-0580-4b12-c16f-591a88393108"
      },
      "source": [
        "sns.countplot(comment_Cleaned_NonWord_Df.isPositive)\n",
        "plt.xlabel('Label')\n",
        "plt.title('Number of Comments')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Number of Comments')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAW8klEQVR4nO3dfZBldX3n8fdHBkEFRaAlMDNxWMU1uKuDTgAfKkVwVUTNYEpd2KCjoqO7mtVaNWK2SkWhoomBVZNQwSAMrlHwaRldshERpIg82AhBnlxaxMwMI9PyjA9kB777x/3N4Tr0DHcGTt/Gfr+qbvU5v9/vnP72ZehPn98595xUFZIkATxm3AVIkuYOQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS1DEU9KiX5PQkx4/peyfJaUluT3LZOGqQHkmGgh5xSW5KsiHJE4ba3pLkgjGW1ZcXAS8BFlXVgTMNSLJ3klOTrE9yd5Lrkxw3/P482iQ5JMnacdehR56hoL7sALxr3EVsqyQ7bOMmTwVuqqqfb2F/uwMXA48Dnl9VuzIIkd2Apz2cWqU+GArqy18A702y2+YdSZYkqSQLhtouSPKWtvzGJP+U5KQkdyS5MckLWvuadhSyYrPd7pnk3PaX+HeSPHVo389sfbcl+WGS1w31nZ7k5CTnJPk58Psz1LtPktVt+6kkb23txwB/Bzw/yT1JjpvhffhvwN3A0VV1E0BVramqd1XVVW0/L0jyvSR3tq8v2Ox9OT7Jd9v3+HqSPZJ8PsldbfySofGV5L8kuaG9Fx9N8rS2/V1Jzkry2KHxr0xyZXufv5vk2UN9NyV5b5KrWm1nJtm5HeH8A7BPq+me9h4dmGSyfZ9bkpw4w/uhua6qfPl6RF/ATcB/AL4KHN/a3gJc0JaXAAUsGNrmAuAtbfmNwEbgTQyOOI4H/gX4a2An4KUMftHu0saf3tZ/r/V/Erio9T0BWNP2tQA4APgZsP/QtncCL2TwR9LOM/w8FwJ/A+wMLAWmgUOHar1oK+/FJcBxW+nfHbgdeH2r76i2vsfQ+zLF4KjiScC1wP9t7+8C4AzgtKH9FXA28ETgWcC9wHnAvxnafkUbewCwATiovc8r2n+7nYb+O14G7NPqvA54e+s7BFi72c9yMfD6trwLcPC4/y362vaXRwrq0weBP04ysR3b/riqTquq+4AzgcXAR6rq3qr6JvCvwNOHxv/vqrqwqu4F/juDv94XA69kML1zWlVtrKorgK8Arx3a9uyq+qequr+qfjVcRNvHC4H3V9WvqupKBkcHbxjx59gDWL+V/lcAN1TV51p9XwCuB141NOa0qvpRVd3J4C/0H1XVt6pqI/AlBr/ch/15Vd1VVdcAVwPfrKobh7bfNH4l8LdVdWlV3VdVqxiEyMFD+/pUVd1cVbcBX2cQilvy/4CnJ9mzqu6pqku2MlZzlKGg3lTV1cA3gGO3Y/NbhpZ/2fa3edsuQ+trhr7vPcBtDP7CfSpwUJseuSPJHcAfAb8107Yz2Ae4raruHmr7CbBwxJ/jVmDvh9j/TzZr23z/m//cW3sftmX8U4H3bPbeLG41bfLToeVfzPC9hh0DPAO4vk1rvXIrYzVHGQrq24eAt/Lrv+Q2nZR9/FDb8C/p7bF400KSXRhMd9zM4Bf+d6pqt6HXLlX1n4e23dqtgm8Gdk+y61DbbwPrRqzrW8Crk2zp/7WbGfxyHrYt+3841gAnbPbePL4drTyUB71nVXVDVR0FPAX4OPDlR/MVVvOVoaBeVdUUg+mf/zrUNs3gl97RSXZI8mYe/pU4hyd5UTuJ+lHgkqpaw+BI5RlJXp9kx/b63SS/M2L9a4DvAn/WTrI+m8FfxP9zxLpOZDC/v2rTye8kC5Oc2PZ1TqvvPyVZkOQ/Avu3uvv2GeDtSQ7KwBOSvGKzANySW4A9kjxpU0OSo5NMVNX9wB2t+f4e6laPDAXNho8wOOE77K3A+xhMrzyLwS/eh+PvGRyV3AY8DzgaoE37vBQ4ksFf5T9l8FfsTtuw76MYnBy/Gfga8KGq+tYoG7a5+BcwmG+/NMndDE783glMVdWtDM57vIfBe/EnwCur6mfbUN92qapJBv8d/orBye0pBifOR9n2euALwI1t6mkf4DDgmiT3MDjZf2RV/bKP2tWfVPmQHUnSgEcKkqSOoSBJ6hgKkqSOoSBJ6ix46CFz15577llLliwZdxmS9Khy+eWX/6yqZrzTwKM6FJYsWcLk5OS4y5CkR5Ukm3+KvuP0kSSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSp86j+RPMj4XnvO2PcJWgOuvwv3jDuEqSx6P1IoT1u8Yok32jr+ya5NMlUkjPb4xNJslNbn2r9S/quTZL062Zj+uhdwHVD6x8HTqqqpzN4BOAxrf0Y4PbWflIbJ0maRb2GQpJFwCuAv2vrAQ4FvtyGrAKOaMvL2zqt/8VtvCRplvR9pPA/GDyI/P62vgdwR1VtbOtrgYVteSGwBqD139nG/5okK5NMJpmcnp7us3ZJmnd6C4UkrwQ2VNXlj+R+q+qUqlpWVcsmJma8HbgkaTv1efXRC4E/SHI4sDPwROCTwG5JFrSjgUXAujZ+HbAYWJtkAfAk4NYe65Mkbaa3I4Wq+kBVLaqqJcCRwLer6o+A84HXtGErgLPb8uq2Tuv/dlVVX/VJkh5sHJ9TeD/wxSTHA1cAp7b2U4HPJZkCbmMQJNK89S8f+ffjLkFz0G9/8Ae97n9WQqGqLgAuaMs3AgfOMOZXwGtnox5J0sy8zYUkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6vYVCkp2TXJbkn5Nck+S41n56kh8nubK9lrb2JPlUkqkkVyV5bl+1SZJm1ueT1+4FDq2qe5LsCFyU5B9a3/uq6subjX85sF97HQSc3L5KkmZJb0cKNXBPW92xvWormywHzmjbXQLslmTvvuqTJD1Yr+cUkuyQ5EpgA3BuVV3auk5oU0QnJdmptS0E1gxtvra1bb7PlUkmk0xOT0/3Wb4kzTu9hkJV3VdVS4FFwIFJ/h3wAeCZwO8CuwPv38Z9nlJVy6pq2cTExCNesyTNZ7Ny9VFV3QGcDxxWVevbFNG9wGnAgW3YOmDx0GaLWpskaZb0efXRRJLd2vLjgJcA1286T5AkwBHA1W2T1cAb2lVIBwN3VtX6vuqTJD1Yn1cf7Q2sSrIDg/A5q6q+keTbSSaAAFcCb2/jzwEOB6aAXwBv6rE2SdIMeguFqroKOGCG9kO3ML6Ad/RVjyTpofmJZklSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHX6fBznzkkuS/LPSa5Jclxr3zfJpUmmkpyZ5LGtfae2PtX6l/RVmyRpZn0eKdwLHFpVzwGWAoe1Zy9/HDipqp4O3A4c08YfA9ze2k9q4yRJs6i3UKiBe9rqju1VwKHAl1v7KuCItry8rdP6X5wkfdUnSXqwXs8pJNkhyZXABuBc4EfAHVW1sQ1ZCyxsywuBNQCt/05gjz7rkyT9ul5Doaruq6qlwCLgQOCZD3efSVYmmUwyOT09/bBrlCQ9YFauPqqqO4DzgecDuyVZ0LoWAeva8jpgMUDrfxJw6wz7OqWqllXVsomJid5rl6T5pM+rjyaS7NaWHwe8BLiOQTi8pg1bAZzdlle3dVr/t6uq+qpPkvRgCx56yHbbG1iVZAcG4XNWVX0jybXAF5McD1wBnNrGnwp8LskUcBtwZI+1SZJm0FsoVNVVwAEztN/I4PzC5u2/Al7bVz2SpIfmJ5olSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSZ0+n9G8OMn5Sa5Nck2Sd7X2DydZl+TK9jp8aJsPJJlK8sMkL+urNknSzPp8RvNG4D1V9f0kuwKXJzm39Z1UVZ8YHpxkfwbPZX4WsA/wrSTPqKr7eqxRkjSktyOFqlpfVd9vy3cD1wELt7LJcuCLVXVvVf0YmGKGZzlLkvozK+cUkiwBDgAubU3vTHJVks8meXJrWwisGdpsLTOESJKVSSaTTE5PT/dYtSTNP72HQpJdgK8A766qu4CTgacBS4H1wF9uy/6q6pSqWlZVyyYmJh7xeiVpPus1FJLsyCAQPl9VXwWoqluq6r6quh/4DA9MEa0DFg9tvqi1SZJmSZ9XHwU4Fbiuqk4cat97aNirgavb8mrgyCQ7JdkX2A+4rK/6JEkP1ufVRy8EXg/8IMmVre1PgaOSLAUKuAl4G0BVXZPkLOBaBlcuvcMrjyRpdvUWClV1EZAZus7ZyjYnACf0VZMkaev8RLMkqTNSKCQ5b5Q2SdKj21anj5LsDDwe2LN9nmDTdNAT2foH0SRJj0IPdU7hbcC7Gdx24nIeCIW7gL/qsS5J0hhsNRSq6pPAJ5P8cVV9epZqkiSNyUhXH1XVp5O8AFgyvE1VndFTXZKkMRgpFJJ8jsGtKa4ENn12oABDQZJ+g4z6OYVlwP5VVX0WI0kar1E/p3A18Ft9FiJJGr9RjxT2BK5Nchlw76bGqvqDXqqSJI3FqKHw4T6LkCTNDaNeffSdvguRJI3fqFcf3c3gaiOAxwI7Aj+vqif2VZgkafaNeqSw66bl9pyE5cDBfRUlSRqPbb5Lag38L+BlPdQjSRqjUaeP/nBo9TEMPrfwq14qkiSNzahHCq8aer0MuJvBFNIWJVmc5Pwk1ya5Jsm7WvvuSc5NckP7+uTWniSfSjKV5Kokz93+H0uStD1GPafwpu3Y90bgPVX1/SS7ApcnORd4I3BeVX0sybHAscD7gZczeC7zfsBBwMntqyRploz6kJ1FSb6WZEN7fSXJoq1tU1Xrq+r7bflu4DoGz2BYDqxqw1YBR7Tl5cAZ7ZzFJcBuSfbejp9JkrSdRp0+Og1YzeC5CvsAX29tI0myBDgAuBTYq6rWt66fAnu15YXAmqHN1jLDg3ySrEwymWRyenp61BIkSSMYNRQmquq0qtrYXqcDE6NsmGQX4CvAu6vqruG+doO9bbrJXlWdUlXLqmrZxMRIJUiSRjRqKNya5OgkO7TX0cCtD7VRkh0ZBMLnq+qrrfmWTdNC7euG1r4OWDy0+aLWJkmaJaOGwpuB1zGY7lkPvIbBCeMtah9yOxW4rqpOHOpaDaxoyyuAs4fa39CuQjoYuHNomkmSNAtGvSHeR4AVVXU7DC4rBT7BICy25IXA64EfJLmytf0p8DHgrCTHAD9hEDYA5wCHA1PAL4DtueJJkvQwjBoKz94UCABVdVuSA7a2QVVdBGQL3S+eYXwB7xixHklSD0adPnrMpg+ZQXekMGqgSJIeJUb9xf6XwMVJvtTWXwuc0E9JkqRxGfUTzWckmQQObU1/WFXX9leWJGkcRp4CaiFgEEjSb7BtvnW2JOk3l6EgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkTm+hkOSzSTYkuXqo7cNJ1iW5sr0OH+r7QJKpJD9M8rK+6pIkbVmfRwqnA4fN0H5SVS1tr3MAkuwPHAk8q23zN0l26LE2SdIMeguFqroQuG3E4cuBL1bVvVX1Y2AKOLCv2iRJMxvHOYV3JrmqTS9teu7zQmDN0Ji1re1BkqxMMplkcnp6uu9aJWleme1QOBl4GrAUWM/g2c/bpKpOqaplVbVsYmLika5Pkua1WQ2Fqrqlqu6rqvuBz/DAFNE6YPHQ0EWtTZI0i2Y1FJLsPbT6amDTlUmrgSOT7JRkX2A/4LLZrE2SBAv62nGSLwCHAHsmWQt8CDgkyVKggJuAtwFU1TVJzgKuBTYC76iq+/qqTZI0s95CoaqOmqH51K2MPwE4oa96JEkPzU80S5I6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqdNbKCT5bJINSa4eats9yblJbmhfn9zak+RTSaaSXJXkuX3VJUnasj6PFE4HDtus7VjgvKraDzivrQO8nMFzmfcDVgIn91iXJGkLeguFqroQuG2z5uXAqra8CjhiqP2MGrgE2C3J3n3VJkma2WyfU9irqta35Z8Ce7XlhcCaoXFrW9uDJFmZZDLJ5PT0dH+VStI8NLYTzVVVQG3HdqdU1bKqWjYxMdFDZZI0f812KNyyaVqofd3Q2tcBi4fGLWptkqRZNNuhsBpY0ZZXAGcPtb+hXYV0MHDn0DSTJGmWLOhrx0m+ABwC7JlkLfAh4GPAWUmOAX4CvK4NPwc4HJgCfgG8qa+6JElb1lsoVNVRW+h68QxjC3hHX7VIkkbjJ5olSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLU6e0hO1uT5CbgbuA+YGNVLUuyO3AmsAS4CXhdVd0+jvokab4a55HC71fV0qpa1taPBc6rqv2A89q6JGkWzaXpo+XAqra8CjhijLVI0rw0rlAo4JtJLk+ysrXtVVXr2/JPgb1m2jDJyiSTSSanp6dno1ZJmjfGck4BeFFVrUvyFODcJNcPd1ZVJamZNqyqU4BTAJYtWzbjGEnS9hnLkUJVrWtfNwBfAw4EbkmyN0D7umEctUnSfDbroZDkCUl23bQMvBS4GlgNrGjDVgBnz3ZtkjTfjWP6aC/ga0k2ff+/r6r/k+R7wFlJjgF+ArxuDLVJ0rw266FQVTcCz5mh/VbgxbNdjyTpAXPpklRJ0pgZCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSeoYCpKkjqEgSerMuVBIcliSHyaZSnLsuOuRpPlkToVCkh2AvwZeDuwPHJVk//FWJUnzx5wKBeBAYKqqbqyqfwW+CCwfc02SNG8sGHcBm1kIrBlaXwscNDwgyUpgZVu9J8kPZ6m2+WBP4GfjLmIuyCdWjLsE/Tr/bW7yoTwSe3nqljrmWig8pKo6BThl3HX8JkoyWVXLxl2HtDn/bc6euTZ9tA5YPLS+qLVJkmbBXAuF7wH7Jdk3yWOBI4HVY65JkuaNOTV9VFUbk7wT+EdgB+CzVXXNmMuaT5yW01zlv81Zkqoadw2SpDlirk0fSZLGyFCQJHUMBXlrEc1ZST6bZEOSq8ddy3xhKMxz3lpEc9zpwGHjLmI+MRTkrUU0Z1XVhcBt465jPjEUNNOtRRaOqRZJY2YoSJI6hoK8tYikjqEgby0iqWMozHNVtRHYdGuR64CzvLWI5ookXwAuBv5tkrVJjhl3Tb/pvM2FJKnjkYIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSCNIcs82jP1wkvf2tX+pT4aCJKljKEjbKcmrklya5Iok30qy11D3c5JcnOSGJG8d2uZ9Sb6X5Kokx42hbGmrDAVp+10EHFxVBzC45fifDPU9GzgUeD7wwST7JHkpsB+D25UvBZ6X5PdmuWZpqxaMuwDpUWwRcGaSvYHHAj8e6ju7qn4J/DLJ+QyC4EXAS4Er2phdGITEhbNXsrR1hoK0/T4NnFhVq5McAnx4qG/z+8cUEODPqupvZ6c8ads5fSRtvyfxwG3GV2zWtzzJzkn2AA5hcDfafwTenGQXgCQLkzxltoqVRuGRgjSaxydZO7R+IoMjgy8luR34NrDvUP9VwPnAnsBHq+pm4OYkvwNcnATgHuBoYEP/5Uuj8S6pkqSO00eSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpM7/B2f26zQOP5X6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sii5p9Mp4fpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e96177a2-a707-4982-8adc-9f48e33c09d2"
      },
      "source": [
        "print(len(comment_Cleaned_NonWord_Df))\n",
        "\n",
        "X = comment_Cleaned_NonWord_Df.Comments1\n",
        "Y = comment_Cleaned_NonWord_Df.isPositive\n",
        "le = LabelEncoder()\n",
        "Y = le.fit_transform(Y)\n",
        "Y = Y.reshape(-1,1)\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)\n",
        "\n",
        "max_words = 50\n",
        "max_len_arr = [50,100,200,250,300,350,400,450,500,550,600,650,700,750,800,850]\n",
        "bench_mark_results=[]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHXtCltm5jt7",
        "outputId": "b3b25eac-895c-4065-c53d-16bce5a220bf"
      },
      "source": [
        "for max_len in max_len_arr:\n",
        "    startTime = time.time()\n",
        "    tok = Tokenizer(num_words=max_words)\n",
        "    tok.fit_on_texts(X_train)\n",
        "    train_sequences = tok.texts_to_sequences(X_train)\n",
        "    train_sequences_matrix = sequence.pad_sequences(train_sequences,maxlen=max_len)\n",
        "\n",
        "    #Define the RNN structure.\n",
        "    def RNN():\n",
        "        inputs = Input(name='inputs',shape=[max_len])\n",
        "        layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
        "        layer = LSTM(10)(layer)\n",
        "        layer = Dense(256,name='FC1')(layer)\n",
        "        layer = Activation('relu')(layer)\n",
        "        layer = Dropout(0.5)(layer)\n",
        "        layer = Dense(1,name='out_layer')(layer)\n",
        "        layer = Activation('sigmoid')(layer)\n",
        "        model = Model(inputs=inputs,outputs=layer)\n",
        "        return model\n",
        "\n",
        "    model = RNN()   \n",
        "    model.compile(loss='mean_absolute_error',optimizer=RMSprop(),metrics=['accuracy'])\n",
        "    \n",
        "    model.fit(train_sequences_matrix,Y_train,batch_size=128,epochs=10,validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n",
        "    \n",
        "    #Process the test set data.\n",
        "    test_sequences = tok.texts_to_sequences(X_test)\n",
        "    test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
        "\n",
        "    #Evaluate the model on the train set and test set.\n",
        "    score_train = model.evaluate(train_sequences_matrix,Y_train)\n",
        "    score_test = model.evaluate(test_sequences_matrix,Y_test)\n",
        "    \n",
        "    val_predict_train = (np.asarray(model.predict(train_sequences_matrix))).round()\n",
        "    val_predict_test = (np.asarray(model.predict(test_sequences_matrix))).round()\n",
        "    precision_train = precision_score(Y_train, val_predict_train,average='micro')\n",
        "    precision_test = precision_score(Y_test, val_predict_test,average='micro')\n",
        "    recall_train = recall_score(Y_train, val_predict_train,average='micro')\n",
        "    recall_test = recall_score(Y_test, val_predict_test,average='micro')\n",
        "    f1_score_train=f1_score(Y_train, val_predict_train,average='micro')\n",
        "    f1_score_test=f1_score(Y_test, val_predict_test,average='micro')\n",
        "\n",
        "    #print('Train set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr_train[0],accr_train[1]))\n",
        "    #print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr_test[0],accr_test[1]))\n",
        "    endTime = time.time()\n",
        "    elapsedTime=endTime-startTime\n",
        "    bench_mark_results.append({'max_len':max_len,                                \n",
        "                                 'Precision[Training](%)':str(round(precision_train,2)*100),\n",
        "                                 'F1-Score[Training](%)':str(round(f1_score_train,2)*100),\n",
        "                                 'Recall[Training](%)':str(round(recall_train,2)*100),\n",
        "                                 'Mean Absolute Error[Training](%)':str(round(score_train[0],2)*100),\n",
        "                                 'Precision[Test](%)':str(round(precision_test,2)*100),\n",
        "                                 'F1-Score[Test](%)':str(round(f1_score_test,2)*100),\n",
        "                                 'Recall[Test](%)':str(round(recall_test,2)*100),\n",
        "                                 'Mean Absolute Error[Test](%)':str(round(score_test[0],2)*100),\n",
        "                                 'Precision_Difference(%)':str((round((precision_train-precision_test),2)*100)),                                           \n",
        "                                 'Elapsed_Time(Sec.)':str(round(elapsedTime,2))})\n",
        "    \n",
        "print(bench_mark_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 209ms/step - loss: 0.4992 - accuracy: 0.5221 - val_loss: 0.4942 - val_accuracy: 0.7578\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.4902 - accuracy: 0.7562 - val_loss: 0.4806 - val_accuracy: 0.8359\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.4743 - accuracy: 0.8365 - val_loss: 0.4597 - val_accuracy: 0.8828\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.4484 - accuracy: 0.8870 - val_loss: 0.4317 - val_accuracy: 0.8438\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.4179 - accuracy: 0.8760 - val_loss: 0.4015 - val_accuracy: 0.8438\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3779 - accuracy: 0.8635 - val_loss: 0.3570 - val_accuracy: 0.8984\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3344 - accuracy: 0.8888 - val_loss: 0.3163 - val_accuracy: 0.8984\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.2917 - accuracy: 0.9078 - val_loss: 0.2927 - val_accuracy: 0.8594\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.2777 - accuracy: 0.8549 - val_loss: 0.2550 - val_accuracy: 0.8750\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.2299 - accuracy: 0.9031 - val_loss: 0.2163 - val_accuracy: 0.8828\n",
            "20/20 [==============================] - 1s 5ms/step - loss: 0.2072 - accuracy: 0.9000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2159 - accuracy: 0.8687\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 234ms/step - loss: 0.4993 - accuracy: 0.5323 - val_loss: 0.4944 - val_accuracy: 0.8047\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.4910 - accuracy: 0.8065 - val_loss: 0.4835 - val_accuracy: 0.8359\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.4784 - accuracy: 0.8302 - val_loss: 0.4672 - val_accuracy: 0.8281\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.4599 - accuracy: 0.8440 - val_loss: 0.4450 - val_accuracy: 0.8281\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.4341 - accuracy: 0.8479 - val_loss: 0.4160 - val_accuracy: 0.8281\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.3996 - accuracy: 0.8648 - val_loss: 0.3804 - val_accuracy: 0.8438\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 268ms/step - loss: 0.3617 - accuracy: 0.8781 - val_loss: 0.3406 - val_accuracy: 0.8672\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.3165 - accuracy: 0.8846 - val_loss: 0.2987 - val_accuracy: 0.8750\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.2854 - accuracy: 0.8831 - val_loss: 0.2604 - val_accuracy: 0.8594\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2377 - accuracy: 0.9055 - val_loss: 0.2271 - val_accuracy: 0.8672\n",
            "20/20 [==============================] - 1s 8ms/step - loss: 0.2150 - accuracy: 0.8922\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2239 - accuracy: 0.8625\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 258ms/step - loss: 0.4994 - accuracy: 0.5047 - val_loss: 0.4960 - val_accuracy: 0.8047\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 0.4932 - accuracy: 0.7935 - val_loss: 0.4853 - val_accuracy: 0.7969\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 99ms/step - loss: 0.4804 - accuracy: 0.8617 - val_loss: 0.4697 - val_accuracy: 0.8594\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 0.4617 - accuracy: 0.8596 - val_loss: 0.4463 - val_accuracy: 0.8359\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 0.4356 - accuracy: 0.8667 - val_loss: 0.4169 - val_accuracy: 0.8438\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 98ms/step - loss: 0.4046 - accuracy: 0.8661 - val_loss: 0.3820 - val_accuracy: 0.8984\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 99ms/step - loss: 0.3671 - accuracy: 0.8766 - val_loss: 0.3426 - val_accuracy: 0.8984\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 94ms/step - loss: 0.3278 - accuracy: 0.8786 - val_loss: 0.3018 - val_accuracy: 0.8750\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 96ms/step - loss: 0.2892 - accuracy: 0.8799 - val_loss: 0.2651 - val_accuracy: 0.9141\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 0.2454 - accuracy: 0.9016 - val_loss: 0.2333 - val_accuracy: 0.8984\n",
            "20/20 [==============================] - 1s 14ms/step - loss: 0.2250 - accuracy: 0.9047\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2371 - accuracy: 0.8687\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 410ms/step - loss: 0.4985 - accuracy: 0.5630 - val_loss: 0.4917 - val_accuracy: 0.8203\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 0.4888 - accuracy: 0.8112 - val_loss: 0.4758 - val_accuracy: 0.8281\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 113ms/step - loss: 0.4704 - accuracy: 0.8443 - val_loss: 0.4536 - val_accuracy: 0.8359\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 114ms/step - loss: 0.4491 - accuracy: 0.8328 - val_loss: 0.4251 - val_accuracy: 0.8516\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 0.4176 - accuracy: 0.8487 - val_loss: 0.3913 - val_accuracy: 0.8594\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.3808 - accuracy: 0.8427 - val_loss: 0.3529 - val_accuracy: 0.8594\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 0.3445 - accuracy: 0.8651 - val_loss: 0.3139 - val_accuracy: 0.8516\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 118ms/step - loss: 0.3024 - accuracy: 0.8727 - val_loss: 0.2781 - val_accuracy: 0.8594\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 0.2689 - accuracy: 0.8784 - val_loss: 0.2457 - val_accuracy: 0.8750\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 113ms/step - loss: 0.2264 - accuracy: 0.9029 - val_loss: 0.2172 - val_accuracy: 0.8984\n",
            "20/20 [==============================] - 1s 19ms/step - loss: 0.2080 - accuracy: 0.9062\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2217 - accuracy: 0.8625\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 319ms/step - loss: 0.4989 - accuracy: 0.5445 - val_loss: 0.4935 - val_accuracy: 0.8594\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.4905 - accuracy: 0.7727 - val_loss: 0.4820 - val_accuracy: 0.8438\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 127ms/step - loss: 0.4769 - accuracy: 0.8435 - val_loss: 0.4636 - val_accuracy: 0.8828\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 129ms/step - loss: 0.4552 - accuracy: 0.8833 - val_loss: 0.4393 - val_accuracy: 0.8984\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 130ms/step - loss: 0.4271 - accuracy: 0.8979 - val_loss: 0.4066 - val_accuracy: 0.8984\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 0.3945 - accuracy: 0.8846 - val_loss: 0.3682 - val_accuracy: 0.8906\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 0.3530 - accuracy: 0.8938 - val_loss: 0.3259 - val_accuracy: 0.8906\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 0.3081 - accuracy: 0.8849 - val_loss: 0.2922 - val_accuracy: 0.9141\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 129ms/step - loss: 0.2685 - accuracy: 0.9000 - val_loss: 0.2497 - val_accuracy: 0.8984\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.2326 - accuracy: 0.9122 - val_loss: 0.2196 - val_accuracy: 0.8672\n",
            "20/20 [==============================] - 1s 20ms/step - loss: 0.2135 - accuracy: 0.8953\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.2204 - accuracy: 0.8687\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 314ms/step - loss: 0.4987 - accuracy: 0.6018 - val_loss: 0.4930 - val_accuracy: 0.8281\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.4901 - accuracy: 0.8229 - val_loss: 0.4801 - val_accuracy: 0.8359\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.4764 - accuracy: 0.8430 - val_loss: 0.4609 - val_accuracy: 0.8359\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.4522 - accuracy: 0.8544 - val_loss: 0.4346 - val_accuracy: 0.8438\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.4246 - accuracy: 0.8573 - val_loss: 0.4004 - val_accuracy: 0.8516\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 0.3900 - accuracy: 0.8513 - val_loss: 0.3596 - val_accuracy: 0.8672\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 0.3504 - accuracy: 0.8685 - val_loss: 0.3184 - val_accuracy: 0.8672\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 0.3073 - accuracy: 0.8745 - val_loss: 0.2812 - val_accuracy: 0.8984\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 0.2647 - accuracy: 0.8924 - val_loss: 0.2432 - val_accuracy: 0.8828\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 155ms/step - loss: 0.2253 - accuracy: 0.9135 - val_loss: 0.2113 - val_accuracy: 0.8750\n",
            "20/20 [==============================] - 1s 23ms/step - loss: 0.2068 - accuracy: 0.8969\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.2162 - accuracy: 0.8813\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 341ms/step - loss: 0.4985 - accuracy: 0.6302 - val_loss: 0.4929 - val_accuracy: 0.8516\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.4889 - accuracy: 0.8391 - val_loss: 0.4799 - val_accuracy: 0.8672\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.4735 - accuracy: 0.8688 - val_loss: 0.4620 - val_accuracy: 0.8750\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.4530 - accuracy: 0.8807 - val_loss: 0.4372 - val_accuracy: 0.8750\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.4249 - accuracy: 0.8914 - val_loss: 0.4072 - val_accuracy: 0.8906\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.3874 - accuracy: 0.8979 - val_loss: 0.3749 - val_accuracy: 0.8984\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.3527 - accuracy: 0.8898 - val_loss: 0.3307 - val_accuracy: 0.9062\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.3216 - accuracy: 0.8823 - val_loss: 0.2922 - val_accuracy: 0.9141\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.2740 - accuracy: 0.9005 - val_loss: 0.2548 - val_accuracy: 0.9141\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.2395 - accuracy: 0.8831 - val_loss: 0.2201 - val_accuracy: 0.8594\n",
            "20/20 [==============================] - 1s 27ms/step - loss: 0.2137 - accuracy: 0.8938\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.2222 - accuracy: 0.8750\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 497ms/step - loss: 0.4993 - accuracy: 0.4961 - val_loss: 0.4963 - val_accuracy: 0.8047\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 191ms/step - loss: 0.4931 - accuracy: 0.7370 - val_loss: 0.4865 - val_accuracy: 0.8203\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 197ms/step - loss: 0.4803 - accuracy: 0.8383 - val_loss: 0.4723 - val_accuracy: 0.8359\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 0.4633 - accuracy: 0.8456 - val_loss: 0.4503 - val_accuracy: 0.8438\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 195ms/step - loss: 0.4365 - accuracy: 0.8651 - val_loss: 0.4216 - val_accuracy: 0.8828\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 197ms/step - loss: 0.4042 - accuracy: 0.8776 - val_loss: 0.3872 - val_accuracy: 0.8594\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 199ms/step - loss: 0.3682 - accuracy: 0.8719 - val_loss: 0.3440 - val_accuracy: 0.8516\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 199ms/step - loss: 0.3237 - accuracy: 0.8961 - val_loss: 0.3035 - val_accuracy: 0.8984\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 195ms/step - loss: 0.2826 - accuracy: 0.8878 - val_loss: 0.2586 - val_accuracy: 0.8672\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 192ms/step - loss: 0.2469 - accuracy: 0.8878 - val_loss: 0.2278 - val_accuracy: 0.9062\n",
            "20/20 [==============================] - 1s 28ms/step - loss: 0.2203 - accuracy: 0.8953\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.2335 - accuracy: 0.8562\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 388ms/step - loss: 0.4989 - accuracy: 0.5695 - val_loss: 0.4932 - val_accuracy: 0.9062\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 0.4893 - accuracy: 0.8109 - val_loss: 0.4797 - val_accuracy: 0.8906\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 0.4733 - accuracy: 0.8682 - val_loss: 0.4593 - val_accuracy: 0.9062\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 0.4493 - accuracy: 0.9026 - val_loss: 0.4323 - val_accuracy: 0.9062\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 0.4193 - accuracy: 0.8859 - val_loss: 0.4017 - val_accuracy: 0.8672\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 216ms/step - loss: 0.3857 - accuracy: 0.8940 - val_loss: 0.3635 - val_accuracy: 0.9219\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.3464 - accuracy: 0.8961 - val_loss: 0.3266 - val_accuracy: 0.9062\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 0.2996 - accuracy: 0.9229 - val_loss: 0.2931 - val_accuracy: 0.8750\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 220ms/step - loss: 0.2722 - accuracy: 0.8961 - val_loss: 0.2550 - val_accuracy: 0.9219\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 0.2288 - accuracy: 0.9237 - val_loss: 0.2299 - val_accuracy: 0.9141\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 0.2189 - accuracy: 0.9125\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.2327 - accuracy: 0.8562\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 402ms/step - loss: 0.4992 - accuracy: 0.5167 - val_loss: 0.4947 - val_accuracy: 0.8359\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.4917 - accuracy: 0.8497 - val_loss: 0.4827 - val_accuracy: 0.8750\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 0.4776 - accuracy: 0.8534 - val_loss: 0.4653 - val_accuracy: 0.8750\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.4584 - accuracy: 0.8438 - val_loss: 0.4407 - val_accuracy: 0.8828\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.4285 - accuracy: 0.8818 - val_loss: 0.4074 - val_accuracy: 0.8438\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.3921 - accuracy: 0.8734 - val_loss: 0.3724 - val_accuracy: 0.8984\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 0.3544 - accuracy: 0.8896 - val_loss: 0.3273 - val_accuracy: 0.8594\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 249ms/step - loss: 0.3123 - accuracy: 0.8826 - val_loss: 0.2856 - val_accuracy: 0.8672\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 239ms/step - loss: 0.2723 - accuracy: 0.8984 - val_loss: 0.2468 - val_accuracy: 0.8594\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 0.2334 - accuracy: 0.8984 - val_loss: 0.2158 - val_accuracy: 0.8750\n",
            "20/20 [==============================] - 2s 36ms/step - loss: 0.2106 - accuracy: 0.8969\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2192 - accuracy: 0.8750\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 422ms/step - loss: 0.4995 - accuracy: 0.5125 - val_loss: 0.4971 - val_accuracy: 0.5781\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 0.4935 - accuracy: 0.6685 - val_loss: 0.4877 - val_accuracy: 0.8516\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 267ms/step - loss: 0.4824 - accuracy: 0.8174 - val_loss: 0.4719 - val_accuracy: 0.8438\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 0.4635 - accuracy: 0.8469 - val_loss: 0.4499 - val_accuracy: 0.8438\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.4357 - accuracy: 0.8773 - val_loss: 0.4192 - val_accuracy: 0.8594\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 256ms/step - loss: 0.4003 - accuracy: 0.8917 - val_loss: 0.3828 - val_accuracy: 0.8672\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 260ms/step - loss: 0.3610 - accuracy: 0.8789 - val_loss: 0.3426 - val_accuracy: 0.9141\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 264ms/step - loss: 0.3223 - accuracy: 0.8875 - val_loss: 0.3024 - val_accuracy: 0.8984\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 259ms/step - loss: 0.2834 - accuracy: 0.8846 - val_loss: 0.2669 - val_accuracy: 0.8672\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 267ms/step - loss: 0.2500 - accuracy: 0.8932 - val_loss: 0.2351 - val_accuracy: 0.8984\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 0.2253 - accuracy: 0.9000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.2357 - accuracy: 0.8625\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 441ms/step - loss: 0.4986 - accuracy: 0.5188 - val_loss: 0.4942 - val_accuracy: 0.6250\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 274ms/step - loss: 0.4901 - accuracy: 0.7055 - val_loss: 0.4819 - val_accuracy: 0.8516\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 280ms/step - loss: 0.4748 - accuracy: 0.8469 - val_loss: 0.4669 - val_accuracy: 0.8516\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 279ms/step - loss: 0.4547 - accuracy: 0.8690 - val_loss: 0.4421 - val_accuracy: 0.8750\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 280ms/step - loss: 0.4299 - accuracy: 0.8711 - val_loss: 0.4139 - val_accuracy: 0.8750\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 274ms/step - loss: 0.3962 - accuracy: 0.8771 - val_loss: 0.3786 - val_accuracy: 0.8984\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 275ms/step - loss: 0.3532 - accuracy: 0.8797 - val_loss: 0.3404 - val_accuracy: 0.8984\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 279ms/step - loss: 0.3209 - accuracy: 0.8987 - val_loss: 0.2983 - val_accuracy: 0.8906\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 274ms/step - loss: 0.2817 - accuracy: 0.8880 - val_loss: 0.2634 - val_accuracy: 0.8594\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 273ms/step - loss: 0.2486 - accuracy: 0.8951 - val_loss: 0.2388 - val_accuracy: 0.9062\n",
            "20/20 [==============================] - 1s 41ms/step - loss: 0.2277 - accuracy: 0.9031\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.2398 - accuracy: 0.8500\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 446ms/step - loss: 0.4989 - accuracy: 0.6091 - val_loss: 0.4948 - val_accuracy: 0.7422\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 283ms/step - loss: 0.4912 - accuracy: 0.7875 - val_loss: 0.4828 - val_accuracy: 0.8438\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 297ms/step - loss: 0.4769 - accuracy: 0.8221 - val_loss: 0.4634 - val_accuracy: 0.8828\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 288ms/step - loss: 0.4565 - accuracy: 0.8607 - val_loss: 0.4358 - val_accuracy: 0.8672\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 293ms/step - loss: 0.4269 - accuracy: 0.8552 - val_loss: 0.4018 - val_accuracy: 0.8672\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 292ms/step - loss: 0.3870 - accuracy: 0.8672 - val_loss: 0.3627 - val_accuracy: 0.8750\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 291ms/step - loss: 0.3520 - accuracy: 0.8609 - val_loss: 0.3222 - val_accuracy: 0.8750\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 296ms/step - loss: 0.3021 - accuracy: 0.8940 - val_loss: 0.2857 - val_accuracy: 0.9141\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 296ms/step - loss: 0.2657 - accuracy: 0.9026 - val_loss: 0.2456 - val_accuracy: 0.9062\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 294ms/step - loss: 0.2280 - accuracy: 0.9078 - val_loss: 0.2165 - val_accuracy: 0.9141\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 0.2116 - accuracy: 0.9094\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.2198 - accuracy: 0.9000\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 472ms/step - loss: 0.4987 - accuracy: 0.5896 - val_loss: 0.4944 - val_accuracy: 0.7812\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 312ms/step - loss: 0.4901 - accuracy: 0.8432 - val_loss: 0.4830 - val_accuracy: 0.7969\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 341ms/step - loss: 0.4768 - accuracy: 0.8484 - val_loss: 0.4659 - val_accuracy: 0.8203\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 316ms/step - loss: 0.4573 - accuracy: 0.8451 - val_loss: 0.4440 - val_accuracy: 0.8203\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 315ms/step - loss: 0.4326 - accuracy: 0.8589 - val_loss: 0.4136 - val_accuracy: 0.8203\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 322ms/step - loss: 0.3986 - accuracy: 0.8672 - val_loss: 0.3754 - val_accuracy: 0.8359\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 312ms/step - loss: 0.3578 - accuracy: 0.8646 - val_loss: 0.3324 - val_accuracy: 0.8438\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 310ms/step - loss: 0.3190 - accuracy: 0.8786 - val_loss: 0.2909 - val_accuracy: 0.8672\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 316ms/step - loss: 0.2719 - accuracy: 0.9036 - val_loss: 0.2529 - val_accuracy: 0.8516\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 327ms/step - loss: 0.2427 - accuracy: 0.8768 - val_loss: 0.2203 - val_accuracy: 0.8594\n",
            "20/20 [==============================] - 2s 55ms/step - loss: 0.2122 - accuracy: 0.8906\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.2200 - accuracy: 0.8687\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 4s 504ms/step - loss: 0.4991 - accuracy: 0.5857 - val_loss: 0.4945 - val_accuracy: 0.6406\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 322ms/step - loss: 0.4901 - accuracy: 0.7448 - val_loss: 0.4796 - val_accuracy: 0.8828\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 325ms/step - loss: 0.4729 - accuracy: 0.8635 - val_loss: 0.4576 - val_accuracy: 0.8281\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 327ms/step - loss: 0.4481 - accuracy: 0.8745 - val_loss: 0.4299 - val_accuracy: 0.8516\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 336ms/step - loss: 0.4201 - accuracy: 0.8667 - val_loss: 0.3949 - val_accuracy: 0.8672\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 322ms/step - loss: 0.3849 - accuracy: 0.8620 - val_loss: 0.3583 - val_accuracy: 0.8984\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 333ms/step - loss: 0.3435 - accuracy: 0.8826 - val_loss: 0.3156 - val_accuracy: 0.8594\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 319ms/step - loss: 0.3028 - accuracy: 0.8844 - val_loss: 0.2770 - val_accuracy: 0.8984\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 318ms/step - loss: 0.2724 - accuracy: 0.8896 - val_loss: 0.2405 - val_accuracy: 0.8828\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 328ms/step - loss: 0.2171 - accuracy: 0.9083 - val_loss: 0.2106 - val_accuracy: 0.9062\n",
            "20/20 [==============================] - 2s 54ms/step - loss: 0.2050 - accuracy: 0.9062\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.2168 - accuracy: 0.8687\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 4s 527ms/step - loss: 0.4987 - accuracy: 0.5445 - val_loss: 0.4962 - val_accuracy: 0.4766\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 349ms/step - loss: 0.4916 - accuracy: 0.5589 - val_loss: 0.4866 - val_accuracy: 0.8281\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 356ms/step - loss: 0.4806 - accuracy: 0.8242 - val_loss: 0.4728 - val_accuracy: 0.8359\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 367ms/step - loss: 0.4625 - accuracy: 0.8466 - val_loss: 0.4516 - val_accuracy: 0.8359\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 359ms/step - loss: 0.4405 - accuracy: 0.8656 - val_loss: 0.4255 - val_accuracy: 0.8438\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 353ms/step - loss: 0.4103 - accuracy: 0.8721 - val_loss: 0.3893 - val_accuracy: 0.8672\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 358ms/step - loss: 0.3724 - accuracy: 0.8721 - val_loss: 0.3536 - val_accuracy: 0.8750\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 363ms/step - loss: 0.3352 - accuracy: 0.8812 - val_loss: 0.3130 - val_accuracy: 0.8594\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 350ms/step - loss: 0.2961 - accuracy: 0.8708 - val_loss: 0.2775 - val_accuracy: 0.8438\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 363ms/step - loss: 0.2629 - accuracy: 0.8773 - val_loss: 0.2486 - val_accuracy: 0.8828\n",
            "20/20 [==============================] - 2s 54ms/step - loss: 0.2374 - accuracy: 0.8938\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.2483 - accuracy: 0.8500\n",
            "[{'max_len': 50, 'Precision[Training](%)': '90.0', 'F1-Score[Training](%)': '90.0', 'Recall[Training](%)': '90.0', 'Mean Absolute Error[Training](%)': '21.0', 'Precision[Test](%)': '87.0', 'F1-Score[Test](%)': '87.0', 'Recall[Test](%)': '87.0', 'Mean Absolute Error[Test](%)': '22.0', 'Precision_Difference(%)': '3.0', 'Elapsed_Time(Sec.)': '5.41'}, {'max_len': 100, 'Precision[Training](%)': '89.0', 'F1-Score[Training](%)': '89.0', 'Recall[Training](%)': '89.0', 'Mean Absolute Error[Training](%)': '22.0', 'Precision[Test](%)': '86.0', 'F1-Score[Test](%)': '86.0', 'Recall[Test](%)': '86.0', 'Mean Absolute Error[Test](%)': '22.0', 'Precision_Difference(%)': '3.0', 'Elapsed_Time(Sec.)': '6.92'}, {'max_len': 200, 'Precision[Training](%)': '90.0', 'F1-Score[Training](%)': '90.0', 'Recall[Training](%)': '90.0', 'Mean Absolute Error[Training](%)': '23.0', 'Precision[Test](%)': '87.0', 'F1-Score[Test](%)': '87.0', 'Recall[Test](%)': '87.0', 'Mean Absolute Error[Test](%)': '24.0', 'Precision_Difference(%)': '4.0', 'Elapsed_Time(Sec.)': '8.01'}, {'max_len': 250, 'Precision[Training](%)': '91.0', 'F1-Score[Training](%)': '91.0', 'Recall[Training](%)': '91.0', 'Mean Absolute Error[Training](%)': '21.0', 'Precision[Test](%)': '86.0', 'F1-Score[Test](%)': '86.0', 'Recall[Test](%)': '86.0', 'Mean Absolute Error[Test](%)': '22.0', 'Precision_Difference(%)': '4.0', 'Elapsed_Time(Sec.)': '9.11'}, {'max_len': 300, 'Precision[Training](%)': '90.0', 'F1-Score[Training](%)': '90.0', 'Recall[Training](%)': '90.0', 'Mean Absolute Error[Training](%)': '21.0', 'Precision[Test](%)': '87.0', 'F1-Score[Test](%)': '87.0', 'Recall[Test](%)': '87.0', 'Mean Absolute Error[Test](%)': '22.0', 'Precision_Difference(%)': '3.0', 'Elapsed_Time(Sec.)': '9.71'}, {'max_len': 350, 'Precision[Training](%)': '90.0', 'F1-Score[Training](%)': '90.0', 'Recall[Training](%)': '90.0', 'Mean Absolute Error[Training](%)': '21.0', 'Precision[Test](%)': '88.0', 'F1-Score[Test](%)': '88.0', 'Recall[Test](%)': '88.0', 'Mean Absolute Error[Test](%)': '22.0', 'Precision_Difference(%)': '2.0', 'Elapsed_Time(Sec.)': '10.91'}, {'max_len': 400, 'Precision[Training](%)': '89.0', 'F1-Score[Training](%)': '89.0', 'Recall[Training](%)': '89.0', 'Mean Absolute Error[Training](%)': '21.0', 'Precision[Test](%)': '88.0', 'F1-Score[Test](%)': '88.0', 'Recall[Test](%)': '88.0', 'Mean Absolute Error[Test](%)': '22.0', 'Precision_Difference(%)': '2.0', 'Elapsed_Time(Sec.)': '11.36'}, {'max_len': 450, 'Precision[Training](%)': '90.0', 'F1-Score[Training](%)': '90.0', 'Recall[Training](%)': '90.0', 'Mean Absolute Error[Training](%)': '22.0', 'Precision[Test](%)': '86.0', 'F1-Score[Test](%)': '86.0', 'Recall[Test](%)': '86.0', 'Mean Absolute Error[Test](%)': '23.0', 'Precision_Difference(%)': '4.0', 'Elapsed_Time(Sec.)': '12.92'}, {'max_len': 500, 'Precision[Training](%)': '91.0', 'F1-Score[Training](%)': '91.0', 'Recall[Training](%)': '91.0', 'Mean Absolute Error[Training](%)': '22.0', 'Precision[Test](%)': '86.0', 'F1-Score[Test](%)': '86.0', 'Recall[Test](%)': '86.0', 'Mean Absolute Error[Test](%)': '23.0', 'Precision_Difference(%)': '6.0', 'Elapsed_Time(Sec.)': '13.63'}, {'max_len': 550, 'Precision[Training](%)': '90.0', 'F1-Score[Training](%)': '90.0', 'Recall[Training](%)': '90.0', 'Mean Absolute Error[Training](%)': '21.0', 'Precision[Test](%)': '88.0', 'F1-Score[Test](%)': '88.0', 'Recall[Test](%)': '88.0', 'Mean Absolute Error[Test](%)': '22.0', 'Precision_Difference(%)': '2.0', 'Elapsed_Time(Sec.)': '15.0'}, {'max_len': 600, 'Precision[Training](%)': '90.0', 'F1-Score[Training](%)': '90.0', 'Recall[Training](%)': '90.0', 'Mean Absolute Error[Training](%)': '23.0', 'Precision[Test](%)': '86.0', 'F1-Score[Test](%)': '86.0', 'Recall[Test](%)': '86.0', 'Mean Absolute Error[Test](%)': '24.0', 'Precision_Difference(%)': '4.0', 'Elapsed_Time(Sec.)': '15.42'}, {'max_len': 650, 'Precision[Training](%)': '90.0', 'F1-Score[Training](%)': '90.0', 'Recall[Training](%)': '90.0', 'Mean Absolute Error[Training](%)': '23.0', 'Precision[Test](%)': '85.0', 'F1-Score[Test](%)': '85.0', 'Recall[Test](%)': '85.0', 'Mean Absolute Error[Test](%)': '24.0', 'Precision_Difference(%)': '5.0', 'Elapsed_Time(Sec.)': '16.63'}, {'max_len': 700, 'Precision[Training](%)': '91.0', 'F1-Score[Training](%)': '91.0', 'Recall[Training](%)': '91.0', 'Mean Absolute Error[Training](%)': '21.0', 'Precision[Test](%)': '90.0', 'F1-Score[Test](%)': '90.0', 'Recall[Test](%)': '90.0', 'Mean Absolute Error[Test](%)': '22.0', 'Precision_Difference(%)': '1.0', 'Elapsed_Time(Sec.)': '16.95'}, {'max_len': 750, 'Precision[Training](%)': '89.0', 'F1-Score[Training](%)': '89.0', 'Recall[Training](%)': '89.0', 'Mean Absolute Error[Training](%)': '21.0', 'Precision[Test](%)': '87.0', 'F1-Score[Test](%)': '87.0', 'Recall[Test](%)': '87.0', 'Mean Absolute Error[Test](%)': '22.0', 'Precision_Difference(%)': '2.0', 'Elapsed_Time(Sec.)': '18.77'}, {'max_len': 800, 'Precision[Training](%)': '91.0', 'F1-Score[Training](%)': '91.0', 'Recall[Training](%)': '91.0', 'Mean Absolute Error[Training](%)': '21.0', 'Precision[Test](%)': '87.0', 'F1-Score[Test](%)': '87.0', 'Recall[Test](%)': '87.0', 'Mean Absolute Error[Test](%)': '22.0', 'Precision_Difference(%)': '4.0', 'Elapsed_Time(Sec.)': '18.87'}, {'max_len': 850, 'Precision[Training](%)': '89.0', 'F1-Score[Training](%)': '89.0', 'Recall[Training](%)': '89.0', 'Mean Absolute Error[Training](%)': '24.0', 'Precision[Test](%)': '85.0', 'F1-Score[Test](%)': '85.0', 'Recall[Test](%)': '85.0', 'Mean Absolute Error[Test](%)': '25.0', 'Precision_Difference(%)': '4.0', 'Elapsed_Time(Sec.)': '20.48'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "my4HGS4vsH-Z",
        "outputId": "4183d5df-3753-4238-9b8f-23ce45153839"
      },
      "source": [
        "df = pd.DataFrame(bench_mark_results)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>max_len</th>\n",
              "      <th>Precision[Training](%)</th>\n",
              "      <th>F1-Score[Training](%)</th>\n",
              "      <th>Recall[Training](%)</th>\n",
              "      <th>Mean Absolute Error[Training](%)</th>\n",
              "      <th>Precision[Test](%)</th>\n",
              "      <th>F1-Score[Test](%)</th>\n",
              "      <th>Recall[Test](%)</th>\n",
              "      <th>Mean Absolute Error[Test](%)</th>\n",
              "      <th>Precision_Difference(%)</th>\n",
              "      <th>Elapsed_Time(Sec.)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100</td>\n",
              "      <td>89.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>200</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>250</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>300</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>350</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>400</td>\n",
              "      <td>89.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>450</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>500</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>550</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>600</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>650</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>700</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>750</td>\n",
              "      <td>89.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>18.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>800</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>18.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>850</td>\n",
              "      <td>89.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>20.48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    max_len Precision[Training](%)  ... Precision_Difference(%) Elapsed_Time(Sec.)\n",
              "0        50                   90.0  ...                     3.0               5.41\n",
              "1       100                   89.0  ...                     3.0               6.92\n",
              "2       200                   90.0  ...                     4.0               8.01\n",
              "3       250                   91.0  ...                     4.0               9.11\n",
              "4       300                   90.0  ...                     3.0               9.71\n",
              "5       350                   90.0  ...                     2.0              10.91\n",
              "6       400                   89.0  ...                     2.0              11.36\n",
              "7       450                   90.0  ...                     4.0              12.92\n",
              "8       500                   91.0  ...                     6.0              13.63\n",
              "9       550                   90.0  ...                     2.0               15.0\n",
              "10      600                   90.0  ...                     4.0              15.42\n",
              "11      650                   90.0  ...                     5.0              16.63\n",
              "12      700                   91.0  ...                     1.0              16.95\n",
              "13      750                   89.0  ...                     2.0              18.77\n",
              "14      800                   91.0  ...                     4.0              18.87\n",
              "15      850                   89.0  ...                     4.0              20.48\n",
              "\n",
              "[16 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuudwuMRNWzg"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qe8WdnDNZqC"
      },
      "source": [
        "max_words_arr = [50,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000,1050,1100,1150,1200]\n",
        "max_len = 50\n",
        "bench_mark_results=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxyqDTmFNc2D",
        "outputId": "407f4eed-ef4b-4a3e-92bf-a3f7d9039b33"
      },
      "source": [
        "for max_words in max_words_arr:\n",
        "    startTime = time.time()\n",
        "    tok = Tokenizer(num_words=max_words)\n",
        "    tok.fit_on_texts(X_train)\n",
        "    train_sequences = tok.texts_to_sequences(X_train)\n",
        "    train_sequences_matrix = sequence.pad_sequences(train_sequences,maxlen=max_len)\n",
        "\n",
        "    #Define the RNN structure.\n",
        "    def RNN():\n",
        "        gru_input = Input(shape=(max_len,))\n",
        "        embedding = Embedding(max_words, 128, input_length=max_len)(gru_input)\n",
        "        gru = GRU(128)(embedding)\n",
        "        dropout = Dropout(0.4)(gru)      \n",
        "        dense = Dense(1)(dropout)\n",
        "        activation = Activation('sigmoid')(dense)\n",
        "        model = Model(gru_input, activation)\n",
        "        model.summary()     \n",
        "        return model\n",
        "\n",
        "    model = RNN()   \n",
        "    model.compile(loss='mean_absolute_error',optimizer=RMSprop(),metrics=['accuracy'])    \n",
        "    model.fit(train_sequences_matrix,Y_train,batch_size=128,epochs=10,validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n",
        "    \n",
        "    #Process the test set data.\n",
        "    test_sequences = tok.texts_to_sequences(X_test)\n",
        "    test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
        "\n",
        "    #Evaluate the model on the train set and test set.\n",
        "    score_train = model.evaluate(train_sequences_matrix,Y_train)\n",
        "    score_test = model.evaluate(test_sequences_matrix,Y_test)\n",
        "    \n",
        "    val_predict_train = (np.asarray(model.predict(train_sequences_matrix))).round()\n",
        "    val_predict_test = (np.asarray(model.predict(test_sequences_matrix))).round()\n",
        "    precision_train = precision_score(Y_train, val_predict_train,average='micro')\n",
        "    precision_test = precision_score(Y_test, val_predict_test,average='micro')\n",
        "    recall_train = recall_score(Y_train, val_predict_train,average='micro')\n",
        "    recall_test = recall_score(Y_test, val_predict_test,average='micro')\n",
        "    f1_score_train=f1_score(Y_train, val_predict_train,average='micro')\n",
        "    f1_score_test=f1_score(Y_test, val_predict_test,average='micro')\n",
        "\n",
        "    endTime = time.time()\n",
        "    elapsedTime=endTime-startTime\n",
        "    bench_mark_results.append({'max_words':max_words,                                \n",
        "                                'Precision[Training](%)':str(round(precision_train,2)*100),\n",
        "                                 'F1-Score[Training](%)':str(round(f1_score_train,2)*100),\n",
        "                                 'Recall[Training](%)':str(round(recall_train,2)*100),\n",
        "                                 'Mean Absolute Error[Training](%)':str(round(score_train[0],2)*100),\n",
        "                                 'Precision[Test](%)':str(round(precision_test,2)*100),\n",
        "                                 'F1-Score[Test](%)':str(round(f1_score_test,2)*100),\n",
        "                                 'Recall[Test](%)':str(round(recall_test,2)*100),\n",
        "                                 'Mean Absolute Error[Test](%)':str(round(score_test[0],2)*100),\n",
        "                                 'Precision_Difference(%)':str((round((precision_train-precision_test),2)*100)),                                           \n",
        "                                 'Elapsed_Time(Sec.)':str(round(elapsedTime,2))})    \n",
        "    \n",
        "print(bench_mark_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_16 (Embedding)     (None, 50, 128)           6400      \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_97 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_112 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 105,601\n",
            "Trainable params: 105,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 317ms/step - loss: 0.4881 - accuracy: 0.7211 - val_loss: 0.4520 - val_accuracy: 0.8047\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.4233 - accuracy: 0.7612 - val_loss: 0.3717 - val_accuracy: 0.8203\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.3318 - accuracy: 0.8276 - val_loss: 0.2828 - val_accuracy: 0.8203\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.2386 - accuracy: 0.8299 - val_loss: 0.2332 - val_accuracy: 0.7812\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.1931 - accuracy: 0.8365 - val_loss: 0.2074 - val_accuracy: 0.8281\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.1695 - accuracy: 0.8508 - val_loss: 0.1961 - val_accuracy: 0.8203\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.1299 - accuracy: 0.8951 - val_loss: 0.2062 - val_accuracy: 0.7969\n",
            "20/20 [==============================] - 1s 15ms/step - loss: 0.1414 - accuracy: 0.8641\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0961 - accuracy: 0.9062\n",
            "Model: \"model_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_17 (Embedding)     (None, 50, 128)           12800     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_98 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_113 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 112,001\n",
            "Trainable params: 112,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 316ms/step - loss: 0.4925 - accuracy: 0.6312 - val_loss: 0.4583 - val_accuracy: 0.8359\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.4246 - accuracy: 0.8302 - val_loss: 0.3460 - val_accuracy: 0.8594\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.3492 - accuracy: 0.7823 - val_loss: 0.2846 - val_accuracy: 0.8516\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.2269 - accuracy: 0.8948 - val_loss: 0.2270 - val_accuracy: 0.8594\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.1648 - accuracy: 0.9253 - val_loss: 0.1915 - val_accuracy: 0.8516\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.1248 - accuracy: 0.9185 - val_loss: 0.1675 - val_accuracy: 0.8594\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.1013 - accuracy: 0.9240 - val_loss: 0.1522 - val_accuracy: 0.8984\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.0852 - accuracy: 0.9456 - val_loss: 0.1376 - val_accuracy: 0.8984\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 181ms/step - loss: 0.0816 - accuracy: 0.9393 - val_loss: 0.1285 - val_accuracy: 0.8984\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.0576 - accuracy: 0.9583 - val_loss: 0.1199 - val_accuracy: 0.8984\n",
            "20/20 [==============================] - 1s 16ms/step - loss: 0.0652 - accuracy: 0.9547\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0637 - accuracy: 0.9438\n",
            "Model: \"model_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_18 (Embedding)     (None, 50, 128)           19200     \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_99 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_114 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 118,401\n",
            "Trainable params: 118,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 318ms/step - loss: 0.4934 - accuracy: 0.5440 - val_loss: 0.4635 - val_accuracy: 0.8125\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.4308 - accuracy: 0.8284 - val_loss: 0.3490 - val_accuracy: 0.8203\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.2996 - accuracy: 0.8367 - val_loss: 0.2802 - val_accuracy: 0.8438\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.2034 - accuracy: 0.9047 - val_loss: 0.2152 - val_accuracy: 0.8594\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.1563 - accuracy: 0.9159 - val_loss: 0.2117 - val_accuracy: 0.8438\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.1354 - accuracy: 0.9221 - val_loss: 0.1670 - val_accuracy: 0.8984\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.0867 - accuracy: 0.9516 - val_loss: 0.1502 - val_accuracy: 0.8594\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.0765 - accuracy: 0.9443 - val_loss: 0.1548 - val_accuracy: 0.8516\n",
            "20/20 [==============================] - 1s 16ms/step - loss: 0.0913 - accuracy: 0.9203\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0729 - accuracy: 0.9375\n",
            "Model: \"model_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_19 (Embedding)     (None, 50, 128)           25600     \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_100 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_115 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 124,801\n",
            "Trainable params: 124,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 314ms/step - loss: 0.4933 - accuracy: 0.5813 - val_loss: 0.4625 - val_accuracy: 0.8281\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.4311 - accuracy: 0.8276 - val_loss: 0.3604 - val_accuracy: 0.7109\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.3151 - accuracy: 0.8247 - val_loss: 0.2767 - val_accuracy: 0.7500\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.2065 - accuracy: 0.8919 - val_loss: 0.2031 - val_accuracy: 0.8672\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.1396 - accuracy: 0.9182 - val_loss: 0.1695 - val_accuracy: 0.8750\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.0967 - accuracy: 0.9401 - val_loss: 0.1565 - val_accuracy: 0.8906\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 0.0803 - accuracy: 0.9417 - val_loss: 0.1484 - val_accuracy: 0.8828\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.0673 - accuracy: 0.9581 - val_loss: 0.1295 - val_accuracy: 0.9062\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.0595 - accuracy: 0.9516 - val_loss: 0.1279 - val_accuracy: 0.8984\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.0516 - accuracy: 0.9570 - val_loss: 0.1212 - val_accuracy: 0.8984\n",
            "20/20 [==============================] - 1s 15ms/step - loss: 0.0574 - accuracy: 0.9516\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0585 - accuracy: 0.9438\n",
            "Model: \"model_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_20 (Embedding)     (None, 50, 128)           32000     \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_101 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_116 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_36 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 131,201\n",
            "Trainable params: 131,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 317ms/step - loss: 0.4947 - accuracy: 0.6404 - val_loss: 0.4679 - val_accuracy: 0.8125\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.4369 - accuracy: 0.8661 - val_loss: 0.4992 - val_accuracy: 0.4766\n",
            "20/20 [==============================] - 1s 17ms/step - loss: 0.4873 - accuracy: 0.4844\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4539 - accuracy: 0.5125\n",
            "Model: \"model_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_21 (Embedding)     (None, 50, 128)           38400     \n",
            "_________________________________________________________________\n",
            "gru_5 (GRU)                  (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_102 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_117 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_37 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 137,601\n",
            "Trainable params: 137,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 318ms/step - loss: 0.4952 - accuracy: 0.5253 - val_loss: 0.4687 - val_accuracy: 0.8125\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.4459 - accuracy: 0.7464 - val_loss: 0.3849 - val_accuracy: 0.8359\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.3235 - accuracy: 0.8526 - val_loss: 0.2776 - val_accuracy: 0.8359\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.2083 - accuracy: 0.8797 - val_loss: 0.2282 - val_accuracy: 0.8438\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.1529 - accuracy: 0.9221 - val_loss: 0.1749 - val_accuracy: 0.8516\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.1014 - accuracy: 0.9328 - val_loss: 0.1586 - val_accuracy: 0.8438\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.0824 - accuracy: 0.9359 - val_loss: 0.1615 - val_accuracy: 0.8516\n",
            "20/20 [==============================] - 1s 16ms/step - loss: 0.0987 - accuracy: 0.9281\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0959 - accuracy: 0.9250\n",
            "Model: \"model_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_22 (Embedding)     (None, 50, 128)           44800     \n",
            "_________________________________________________________________\n",
            "gru_6 (GRU)                  (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_103 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_118 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_38 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 144,001\n",
            "Trainable params: 144,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 329ms/step - loss: 0.4932 - accuracy: 0.6130 - val_loss: 0.4582 - val_accuracy: 0.8359\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.4303 - accuracy: 0.8219 - val_loss: 0.3485 - val_accuracy: 0.8359\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.2881 - accuracy: 0.8914 - val_loss: 0.2471 - val_accuracy: 0.8594\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.2000 - accuracy: 0.9010 - val_loss: 0.1914 - val_accuracy: 0.8672\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.1218 - accuracy: 0.9451 - val_loss: 0.1623 - val_accuracy: 0.8828\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.0933 - accuracy: 0.9599 - val_loss: 0.1468 - val_accuracy: 0.8828\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.0793 - accuracy: 0.9461 - val_loss: 0.1370 - val_accuracy: 0.8906\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.0664 - accuracy: 0.9576 - val_loss: 0.1452 - val_accuracy: 0.8594\n",
            "20/20 [==============================] - 1s 16ms/step - loss: 0.0816 - accuracy: 0.9344\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0684 - accuracy: 0.9375\n",
            "Model: \"model_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_23 (Embedding)     (None, 50, 128)           51200     \n",
            "_________________________________________________________________\n",
            "gru_7 (GRU)                  (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_104 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_119 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_39 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 150,401\n",
            "Trainable params: 150,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 323ms/step - loss: 0.4939 - accuracy: 0.6068 - val_loss: 0.4662 - val_accuracy: 0.8281\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.4351 - accuracy: 0.8768 - val_loss: 0.4334 - val_accuracy: 0.4922\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.3570 - accuracy: 0.7294 - val_loss: 0.2860 - val_accuracy: 0.8516\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.2214 - accuracy: 0.9029 - val_loss: 0.2211 - val_accuracy: 0.8594\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.1626 - accuracy: 0.9302 - val_loss: 0.1820 - val_accuracy: 0.8750\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.1367 - accuracy: 0.9042 - val_loss: 0.1768 - val_accuracy: 0.8984\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.1038 - accuracy: 0.9521 - val_loss: 0.1499 - val_accuracy: 0.8828\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.0732 - accuracy: 0.9529 - val_loss: 0.1390 - val_accuracy: 0.8906\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.0637 - accuracy: 0.9633 - val_loss: 0.1260 - val_accuracy: 0.9062\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.0565 - accuracy: 0.9667 - val_loss: 0.1363 - val_accuracy: 0.8438\n",
            "20/20 [==============================] - 1s 16ms/step - loss: 0.0722 - accuracy: 0.9344\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0676 - accuracy: 0.9438\n",
            "Model: \"model_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_24 (Embedding)     (None, 50, 128)           57600     \n",
            "_________________________________________________________________\n",
            "gru_8 (GRU)                  (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_105 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_120 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_40 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 156,801\n",
            "Trainable params: 156,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 456ms/step - loss: 0.4935 - accuracy: 0.6440 - val_loss: 0.4630 - val_accuracy: 0.8047\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.4339 - accuracy: 0.8115 - val_loss: 0.3575 - val_accuracy: 0.8125\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.2903 - accuracy: 0.8617 - val_loss: 0.2733 - val_accuracy: 0.7500\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.2175 - accuracy: 0.8549 - val_loss: 0.1974 - val_accuracy: 0.8672\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.1271 - accuracy: 0.9380 - val_loss: 0.1648 - val_accuracy: 0.8984\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.0990 - accuracy: 0.9398 - val_loss: 0.1492 - val_accuracy: 0.8750\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.0764 - accuracy: 0.9440 - val_loss: 0.1466 - val_accuracy: 0.8828\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.0640 - accuracy: 0.9708 - val_loss: 0.1383 - val_accuracy: 0.8672\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 0.0501 - accuracy: 0.9721 - val_loss: 0.1175 - val_accuracy: 0.9141\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 0.0478 - accuracy: 0.9656 - val_loss: 0.1125 - val_accuracy: 0.9062\n",
            "20/20 [==============================] - 1s 16ms/step - loss: 0.0535 - accuracy: 0.9641\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0583 - accuracy: 0.9500\n",
            "Model: \"model_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_25 (Embedding)     (None, 50, 128)           64000     \n",
            "_________________________________________________________________\n",
            "gru_9 (GRU)                  (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_106 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_121 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_41 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 163,201\n",
            "Trainable params: 163,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 324ms/step - loss: 0.4920 - accuracy: 0.6451 - val_loss: 0.4577 - val_accuracy: 0.8047\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.4245 - accuracy: 0.8029 - val_loss: 0.3648 - val_accuracy: 0.7109\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.3087 - accuracy: 0.8234 - val_loss: 0.2572 - val_accuracy: 0.8359\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.1805 - accuracy: 0.9026 - val_loss: 0.1979 - val_accuracy: 0.8594\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.1340 - accuracy: 0.9094 - val_loss: 0.1709 - val_accuracy: 0.8594\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.0946 - accuracy: 0.9372 - val_loss: 0.1956 - val_accuracy: 0.8438\n",
            "20/20 [==============================] - 1s 17ms/step - loss: 0.1370 - accuracy: 0.9094\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1418 - accuracy: 0.9000\n",
            "Model: \"model_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_26 (Embedding)     (None, 50, 128)           70400     \n",
            "_________________________________________________________________\n",
            "gru_10 (GRU)                 (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_107 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_122 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_42 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 169,601\n",
            "Trainable params: 169,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 311ms/step - loss: 0.4940 - accuracy: 0.5724 - val_loss: 0.4642 - val_accuracy: 0.8281\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.4299 - accuracy: 0.8906 - val_loss: 0.5122 - val_accuracy: 0.4766\n",
            "20/20 [==============================] - 1s 15ms/step - loss: 0.5015 - accuracy: 0.4844\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4719 - accuracy: 0.5125\n",
            "Model: \"model_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_27 (Embedding)     (None, 50, 128)           76800     \n",
            "_________________________________________________________________\n",
            "gru_11 (GRU)                 (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_108 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_123 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_43 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 176,001\n",
            "Trainable params: 176,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 324ms/step - loss: 0.4941 - accuracy: 0.6344 - val_loss: 0.4699 - val_accuracy: 0.8203\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.4408 - accuracy: 0.8628 - val_loss: 0.5158 - val_accuracy: 0.4766\n",
            "20/20 [==============================] - 1s 16ms/step - loss: 0.5063 - accuracy: 0.4844\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4764 - accuracy: 0.5125\n",
            "Model: \"model_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_28 (Embedding)     (None, 50, 128)           83200     \n",
            "_________________________________________________________________\n",
            "gru_12 (GRU)                 (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_109 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_124 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_44 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 182,401\n",
            "Trainable params: 182,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 325ms/step - loss: 0.4928 - accuracy: 0.6503 - val_loss: 0.4633 - val_accuracy: 0.8047\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.4344 - accuracy: 0.8615 - val_loss: 0.3730 - val_accuracy: 0.8125\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.3119 - accuracy: 0.8878 - val_loss: 0.2984 - val_accuracy: 0.7812\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.2216 - accuracy: 0.8818 - val_loss: 0.2099 - val_accuracy: 0.8750\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.1542 - accuracy: 0.9201 - val_loss: 0.1790 - val_accuracy: 0.8594\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.1072 - accuracy: 0.9354 - val_loss: 0.1643 - val_accuracy: 0.9062\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 0.0919 - accuracy: 0.9349 - val_loss: 0.1449 - val_accuracy: 0.8594\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 0.0743 - accuracy: 0.9586 - val_loss: 0.1368 - val_accuracy: 0.8828\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.0605 - accuracy: 0.9542 - val_loss: 0.1335 - val_accuracy: 0.8984\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.0536 - accuracy: 0.9641 - val_loss: 0.1227 - val_accuracy: 0.9062\n",
            "20/20 [==============================] - 1s 16ms/step - loss: 0.0585 - accuracy: 0.9609\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0578 - accuracy: 0.9500\n",
            "Model: \"model_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_14 (InputLayer)        [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_29 (Embedding)     (None, 50, 128)           89600     \n",
            "_________________________________________________________________\n",
            "gru_13 (GRU)                 (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_110 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_125 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_45 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 188,801\n",
            "Trainable params: 188,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 327ms/step - loss: 0.4924 - accuracy: 0.6138 - val_loss: 0.4624 - val_accuracy: 0.8203\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.4295 - accuracy: 0.8680 - val_loss: 0.3739 - val_accuracy: 0.6953\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.3038 - accuracy: 0.8331 - val_loss: 0.2676 - val_accuracy: 0.8438\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.2060 - accuracy: 0.8997 - val_loss: 0.2059 - val_accuracy: 0.8594\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.1352 - accuracy: 0.9367 - val_loss: 0.2012 - val_accuracy: 0.8594\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.1124 - accuracy: 0.9464 - val_loss: 0.1596 - val_accuracy: 0.8672\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.0797 - accuracy: 0.9500 - val_loss: 0.1597 - val_accuracy: 0.8516\n",
            "20/20 [==============================] - 1s 16ms/step - loss: 0.0939 - accuracy: 0.9266\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0780 - accuracy: 0.9375\n",
            "Model: \"model_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_15 (InputLayer)        [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_30 (Embedding)     (None, 50, 128)           96000     \n",
            "_________________________________________________________________\n",
            "gru_14 (GRU)                 (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_111 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_126 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_46 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 195,201\n",
            "Trainable params: 195,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 333ms/step - loss: 0.4941 - accuracy: 0.5773 - val_loss: 0.4669 - val_accuracy: 0.8203\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.4414 - accuracy: 0.8302 - val_loss: 0.3892 - val_accuracy: 0.8047\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.3354 - accuracy: 0.9086 - val_loss: 0.2735 - val_accuracy: 0.8438\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.2313 - accuracy: 0.8680 - val_loss: 0.2590 - val_accuracy: 0.8047\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.2017 - accuracy: 0.8906 - val_loss: 0.2128 - val_accuracy: 0.8594\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.1313 - accuracy: 0.9341 - val_loss: 0.1802 - val_accuracy: 0.8672\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.1007 - accuracy: 0.9490 - val_loss: 0.1604 - val_accuracy: 0.8672\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.0802 - accuracy: 0.9604 - val_loss: 0.1593 - val_accuracy: 0.8906\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.0761 - accuracy: 0.9581 - val_loss: 0.1360 - val_accuracy: 0.8828\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.0641 - accuracy: 0.9633 - val_loss: 0.1283 - val_accuracy: 0.9062\n",
            "20/20 [==============================] - 1s 17ms/step - loss: 0.0638 - accuracy: 0.9594\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0639 - accuracy: 0.9438\n",
            "Model: \"model_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_16 (InputLayer)        [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_31 (Embedding)     (None, 50, 128)           102400    \n",
            "_________________________________________________________________\n",
            "gru_15 (GRU)                 (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_112 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_127 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_47 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 201,601\n",
            "Trainable params: 201,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 321ms/step - loss: 0.4932 - accuracy: 0.6464 - val_loss: 0.4654 - val_accuracy: 0.8203\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.4344 - accuracy: 0.8693 - val_loss: 0.3620 - val_accuracy: 0.7266\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.3187 - accuracy: 0.8109 - val_loss: 0.2830 - val_accuracy: 0.8438\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.2216 - accuracy: 0.9021 - val_loss: 0.2223 - val_accuracy: 0.8438\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 0.1589 - accuracy: 0.9143 - val_loss: 0.1894 - val_accuracy: 0.8750\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.1122 - accuracy: 0.9401 - val_loss: 0.1815 - val_accuracy: 0.8672\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.0955 - accuracy: 0.9471 - val_loss: 0.1439 - val_accuracy: 0.8750\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.0654 - accuracy: 0.9576 - val_loss: 0.1396 - val_accuracy: 0.8516\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.0630 - accuracy: 0.9521 - val_loss: 0.1446 - val_accuracy: 0.8828\n",
            "20/20 [==============================] - 1s 17ms/step - loss: 0.0769 - accuracy: 0.9484\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0753 - accuracy: 0.9500\n",
            "Model: \"model_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_17 (InputLayer)        [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_32 (Embedding)     (None, 50, 128)           108800    \n",
            "_________________________________________________________________\n",
            "gru_16 (GRU)                 (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_113 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_128 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_48 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 208,001\n",
            "Trainable params: 208,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 324ms/step - loss: 0.4931 - accuracy: 0.6638 - val_loss: 0.4605 - val_accuracy: 0.8203\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.4270 - accuracy: 0.8576 - val_loss: 0.5233 - val_accuracy: 0.4766\n",
            "20/20 [==============================] - 1s 17ms/step - loss: 0.5154 - accuracy: 0.4844\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4873 - accuracy: 0.5125\n",
            "Model: \"model_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_18 (InputLayer)        [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_33 (Embedding)     (None, 50, 128)           115200    \n",
            "_________________________________________________________________\n",
            "gru_17 (GRU)                 (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_114 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_129 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_49 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 214,401\n",
            "Trainable params: 214,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 326ms/step - loss: 0.4914 - accuracy: 0.6987 - val_loss: 0.4551 - val_accuracy: 0.7969\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 0.4206 - accuracy: 0.8404 - val_loss: 0.3511 - val_accuracy: 0.8281\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.2887 - accuracy: 0.8826 - val_loss: 0.2454 - val_accuracy: 0.8594\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.1914 - accuracy: 0.8930 - val_loss: 0.2450 - val_accuracy: 0.7891\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.1558 - accuracy: 0.9148 - val_loss: 0.1768 - val_accuracy: 0.8750\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.0947 - accuracy: 0.9576 - val_loss: 0.1592 - val_accuracy: 0.8906\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.0749 - accuracy: 0.9630 - val_loss: 0.1563 - val_accuracy: 0.8438\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.0769 - accuracy: 0.9536 - val_loss: 0.1362 - val_accuracy: 0.8984\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.0591 - accuracy: 0.9612 - val_loss: 0.1301 - val_accuracy: 0.8906\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.0587 - accuracy: 0.9599 - val_loss: 0.1198 - val_accuracy: 0.9062\n",
            "20/20 [==============================] - 1s 17ms/step - loss: 0.0571 - accuracy: 0.9594\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0550 - accuracy: 0.9625\n",
            "Model: \"model_34\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_19 (InputLayer)        [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_34 (Embedding)     (None, 50, 128)           121600    \n",
            "_________________________________________________________________\n",
            "gru_18 (GRU)                 (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_115 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_130 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_50 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 220,801\n",
            "Trainable params: 220,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 326ms/step - loss: 0.4920 - accuracy: 0.6380 - val_loss: 0.4554 - val_accuracy: 0.8281\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.4255 - accuracy: 0.8216 - val_loss: 0.3547 - val_accuracy: 0.7188\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.2904 - accuracy: 0.8401 - val_loss: 0.2698 - val_accuracy: 0.7500\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.2137 - accuracy: 0.8583 - val_loss: 0.1989 - val_accuracy: 0.8516\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.1380 - accuracy: 0.9195 - val_loss: 0.1727 - val_accuracy: 0.8516\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.0995 - accuracy: 0.9411 - val_loss: 0.1559 - val_accuracy: 0.8906\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.0814 - accuracy: 0.9482 - val_loss: 0.1465 - val_accuracy: 0.8672\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.0697 - accuracy: 0.9487 - val_loss: 0.1432 - val_accuracy: 0.8906\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.0640 - accuracy: 0.9576 - val_loss: 0.1251 - val_accuracy: 0.8984\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.0537 - accuracy: 0.9719 - val_loss: 0.1160 - val_accuracy: 0.9062\n",
            "20/20 [==============================] - 1s 17ms/step - loss: 0.0542 - accuracy: 0.9609\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0553 - accuracy: 0.9500\n",
            "Model: \"model_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_20 (InputLayer)        [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_35 (Embedding)     (None, 50, 128)           128000    \n",
            "_________________________________________________________________\n",
            "gru_19 (GRU)                 (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_116 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_131 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_51 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 227,201\n",
            "Trainable params: 227,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 330ms/step - loss: 0.4909 - accuracy: 0.6380 - val_loss: 0.4537 - val_accuracy: 0.8203\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 184ms/step - loss: 0.4138 - accuracy: 0.8438 - val_loss: 0.3632 - val_accuracy: 0.7422\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.3033 - accuracy: 0.8445 - val_loss: 0.2759 - val_accuracy: 0.7812\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.2061 - accuracy: 0.8828 - val_loss: 0.1957 - val_accuracy: 0.8750\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.1715 - accuracy: 0.8833 - val_loss: 0.2116 - val_accuracy: 0.8438\n",
            "20/20 [==============================] - 1s 18ms/step - loss: 0.1570 - accuracy: 0.9141\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1604 - accuracy: 0.9062\n",
            "Model: \"model_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_21 (InputLayer)        [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_36 (Embedding)     (None, 50, 128)           134400    \n",
            "_________________________________________________________________\n",
            "gru_20 (GRU)                 (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_117 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_132 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_52 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 233,601\n",
            "Trainable params: 233,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 329ms/step - loss: 0.4935 - accuracy: 0.6302 - val_loss: 0.4636 - val_accuracy: 0.8125\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.4368 - accuracy: 0.8672 - val_loss: 0.3797 - val_accuracy: 0.6562\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.3303 - accuracy: 0.7953 - val_loss: 0.2690 - val_accuracy: 0.8438\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.2058 - accuracy: 0.8896 - val_loss: 0.2195 - val_accuracy: 0.8594\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 179ms/step - loss: 0.1448 - accuracy: 0.9398 - val_loss: 0.1753 - val_accuracy: 0.8594\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 188ms/step - loss: 0.1032 - accuracy: 0.9388 - val_loss: 0.1557 - val_accuracy: 0.9062\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.0893 - accuracy: 0.9539 - val_loss: 0.1500 - val_accuracy: 0.8516\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.0627 - accuracy: 0.9643 - val_loss: 0.1296 - val_accuracy: 0.8984\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 174ms/step - loss: 0.0438 - accuracy: 0.9776 - val_loss: 0.1190 - val_accuracy: 0.9141\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.0540 - accuracy: 0.9693 - val_loss: 0.1156 - val_accuracy: 0.9062\n",
            "20/20 [==============================] - 1s 19ms/step - loss: 0.0543 - accuracy: 0.9641\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0577 - accuracy: 0.9500\n",
            "Model: \"model_37\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_22 (InputLayer)        [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_37 (Embedding)     (None, 50, 128)           140800    \n",
            "_________________________________________________________________\n",
            "gru_21 (GRU)                 (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_118 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_133 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_53 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 240,001\n",
            "Trainable params: 240,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 328ms/step - loss: 0.4925 - accuracy: 0.6310 - val_loss: 0.4594 - val_accuracy: 0.8125\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.4293 - accuracy: 0.8362 - val_loss: 0.3561 - val_accuracy: 0.8203\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 0.3004 - accuracy: 0.8508 - val_loss: 0.2444 - val_accuracy: 0.8359\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 0.1748 - accuracy: 0.9177 - val_loss: 0.1885 - val_accuracy: 0.8672\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.1384 - accuracy: 0.9062 - val_loss: 0.1732 - val_accuracy: 0.8906\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.1011 - accuracy: 0.9323 - val_loss: 0.1506 - val_accuracy: 0.8594\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 183ms/step - loss: 0.0748 - accuracy: 0.9477 - val_loss: 0.1431 - val_accuracy: 0.8984\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 177ms/step - loss: 0.0623 - accuracy: 0.9589 - val_loss: 0.1320 - val_accuracy: 0.8750\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 176ms/step - loss: 0.0634 - accuracy: 0.9500 - val_loss: 0.1435 - val_accuracy: 0.8750\n",
            "20/20 [==============================] - 1s 17ms/step - loss: 0.0806 - accuracy: 0.9453\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0800 - accuracy: 0.9500\n",
            "Model: \"model_38\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_23 (InputLayer)        [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_38 (Embedding)     (None, 50, 128)           147200    \n",
            "_________________________________________________________________\n",
            "gru_22 (GRU)                 (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_119 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_134 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_54 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 246,401\n",
            "Trainable params: 246,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 324ms/step - loss: 0.4936 - accuracy: 0.6180 - val_loss: 0.4629 - val_accuracy: 0.8047\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.4300 - accuracy: 0.8174 - val_loss: 0.3637 - val_accuracy: 0.6875\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 178ms/step - loss: 0.3171 - accuracy: 0.8065 - val_loss: 0.2722 - val_accuracy: 0.8359\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 0.2132 - accuracy: 0.8737 - val_loss: 0.2112 - val_accuracy: 0.8516\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 190ms/step - loss: 0.1463 - accuracy: 0.9156 - val_loss: 0.2195 - val_accuracy: 0.8438\n",
            "20/20 [==============================] - 1s 18ms/step - loss: 0.1659 - accuracy: 0.9094\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1702 - accuracy: 0.9125\n",
            "Model: \"model_39\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_24 (InputLayer)        [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_39 (Embedding)     (None, 50, 128)           153600    \n",
            "_________________________________________________________________\n",
            "gru_23 (GRU)                 (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dropout_120 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_135 (Dense)            (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation_55 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 252,801\n",
            "Trainable params: 252,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 319ms/step - loss: 0.4933 - accuracy: 0.6898 - val_loss: 0.4636 - val_accuracy: 0.8203\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.4321 - accuracy: 0.8612 - val_loss: 0.3339 - val_accuracy: 0.8281\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.3308 - accuracy: 0.7922 - val_loss: 0.2609 - val_accuracy: 0.8594\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 180ms/step - loss: 0.1856 - accuracy: 0.9253 - val_loss: 0.2935 - val_accuracy: 0.7266\n",
            "20/20 [==============================] - 1s 18ms/step - loss: 0.2556 - accuracy: 0.7625\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2632 - accuracy: 0.7625\n",
            "[{'max_words': 50, 'Precision[Training](%)': '86.0', 'F1-Score[Training](%)': '86.0', 'Recall[Training](%)': '86.0', 'Mean Absolute Error[Training](%)': '14.000000000000002', 'Precision[Test](%)': '91.0', 'F1-Score[Test](%)': '91.0', 'Recall[Test](%)': '91.0', 'Mean Absolute Error[Test](%)': '10.0', 'Precision_Difference(%)': '-4.0', 'Elapsed_Time(Sec.)': '8.68'}, {'max_words': 100, 'Precision[Training](%)': '95.0', 'F1-Score[Training](%)': '95.0', 'Recall[Training](%)': '95.0', 'Mean Absolute Error[Training](%)': '7.000000000000001', 'Precision[Test](%)': '94.0', 'F1-Score[Test](%)': '94.0', 'Recall[Test](%)': '94.0', 'Mean Absolute Error[Test](%)': '6.0', 'Precision_Difference(%)': '1.0', 'Elapsed_Time(Sec.)': '10.67'}, {'max_words': 150, 'Precision[Training](%)': '92.0', 'F1-Score[Training](%)': '92.0', 'Recall[Training](%)': '92.0', 'Mean Absolute Error[Training](%)': '9.0', 'Precision[Test](%)': '94.0', 'F1-Score[Test](%)': '94.0', 'Recall[Test](%)': '94.0', 'Mean Absolute Error[Test](%)': '7.000000000000001', 'Precision_Difference(%)': '-2.0', 'Elapsed_Time(Sec.)': '9.72'}, {'max_words': 200, 'Precision[Training](%)': '95.0', 'F1-Score[Training](%)': '95.0', 'Recall[Training](%)': '95.0', 'Mean Absolute Error[Training](%)': '6.0', 'Precision[Test](%)': '94.0', 'F1-Score[Test](%)': '94.0', 'Recall[Test](%)': '94.0', 'Mean Absolute Error[Test](%)': '6.0', 'Precision_Difference(%)': '1.0', 'Elapsed_Time(Sec.)': '10.57'}, {'max_words': 250, 'Precision[Training](%)': '48.0', 'F1-Score[Training](%)': '48.0', 'Recall[Training](%)': '48.0', 'Mean Absolute Error[Training](%)': '49.0', 'Precision[Test](%)': '51.0', 'F1-Score[Test](%)': '51.0', 'Recall[Test](%)': '51.0', 'Mean Absolute Error[Test](%)': '45.0', 'Precision_Difference(%)': '-3.0', 'Elapsed_Time(Sec.)': '5.71'}, {'max_words': 300, 'Precision[Training](%)': '93.0', 'F1-Score[Training](%)': '93.0', 'Recall[Training](%)': '93.0', 'Mean Absolute Error[Training](%)': '10.0', 'Precision[Test](%)': '92.0', 'F1-Score[Test](%)': '92.0', 'Recall[Test](%)': '92.0', 'Mean Absolute Error[Test](%)': '10.0', 'Precision_Difference(%)': '0.0', 'Elapsed_Time(Sec.)': '8.64'}, {'max_words': 350, 'Precision[Training](%)': '93.0', 'F1-Score[Training](%)': '93.0', 'Recall[Training](%)': '93.0', 'Mean Absolute Error[Training](%)': '8.0', 'Precision[Test](%)': '94.0', 'F1-Score[Test](%)': '94.0', 'Recall[Test](%)': '94.0', 'Mean Absolute Error[Test](%)': '7.000000000000001', 'Precision_Difference(%)': '-0.0', 'Elapsed_Time(Sec.)': '9.74'}, {'max_words': 400, 'Precision[Training](%)': '93.0', 'F1-Score[Training](%)': '93.0', 'Recall[Training](%)': '93.0', 'Mean Absolute Error[Training](%)': '7.000000000000001', 'Precision[Test](%)': '94.0', 'F1-Score[Test](%)': '94.0', 'Recall[Test](%)': '94.0', 'Mean Absolute Error[Test](%)': '7.000000000000001', 'Precision_Difference(%)': '-1.0', 'Elapsed_Time(Sec.)': '10.56'}, {'max_words': 450, 'Precision[Training](%)': '96.0', 'F1-Score[Training](%)': '96.0', 'Recall[Training](%)': '96.0', 'Mean Absolute Error[Training](%)': '5.0', 'Precision[Test](%)': '95.0', 'F1-Score[Test](%)': '95.0', 'Recall[Test](%)': '95.0', 'Mean Absolute Error[Test](%)': '6.0', 'Precision_Difference(%)': '1.0', 'Elapsed_Time(Sec.)': '11.01'}, {'max_words': 500, 'Precision[Training](%)': '91.0', 'F1-Score[Training](%)': '91.0', 'Recall[Training](%)': '91.0', 'Mean Absolute Error[Training](%)': '14.000000000000002', 'Precision[Test](%)': '90.0', 'F1-Score[Test](%)': '90.0', 'Recall[Test](%)': '90.0', 'Mean Absolute Error[Test](%)': '14.000000000000002', 'Precision_Difference(%)': '1.0', 'Elapsed_Time(Sec.)': '8.0'}, {'max_words': 550, 'Precision[Training](%)': '48.0', 'F1-Score[Training](%)': '48.0', 'Recall[Training](%)': '48.0', 'Mean Absolute Error[Training](%)': '50.0', 'Precision[Test](%)': '51.0', 'F1-Score[Test](%)': '51.0', 'Recall[Test](%)': '51.0', 'Mean Absolute Error[Test](%)': '47.0', 'Precision_Difference(%)': '-3.0', 'Elapsed_Time(Sec.)': '5.26'}, {'max_words': 600, 'Precision[Training](%)': '48.0', 'F1-Score[Training](%)': '48.0', 'Recall[Training](%)': '48.0', 'Mean Absolute Error[Training](%)': '51.0', 'Precision[Test](%)': '51.0', 'F1-Score[Test](%)': '51.0', 'Recall[Test](%)': '51.0', 'Mean Absolute Error[Test](%)': '48.0', 'Precision_Difference(%)': '-3.0', 'Elapsed_Time(Sec.)': '5.76'}, {'max_words': 650, 'Precision[Training](%)': '96.0', 'F1-Score[Training](%)': '96.0', 'Recall[Training](%)': '96.0', 'Mean Absolute Error[Training](%)': '6.0', 'Precision[Test](%)': '95.0', 'F1-Score[Test](%)': '95.0', 'Recall[Test](%)': '95.0', 'Mean Absolute Error[Test](%)': '6.0', 'Precision_Difference(%)': '1.0', 'Elapsed_Time(Sec.)': '10.76'}, {'max_words': 700, 'Precision[Training](%)': '93.0', 'F1-Score[Training](%)': '93.0', 'Recall[Training](%)': '93.0', 'Mean Absolute Error[Training](%)': '9.0', 'Precision[Test](%)': '94.0', 'F1-Score[Test](%)': '94.0', 'Recall[Test](%)': '94.0', 'Mean Absolute Error[Test](%)': '8.0', 'Precision_Difference(%)': '-1.0', 'Elapsed_Time(Sec.)': '9.32'}, {'max_words': 750, 'Precision[Training](%)': '96.0', 'F1-Score[Training](%)': '96.0', 'Recall[Training](%)': '96.0', 'Mean Absolute Error[Training](%)': '6.0', 'Precision[Test](%)': '94.0', 'F1-Score[Test](%)': '94.0', 'Recall[Test](%)': '94.0', 'Mean Absolute Error[Test](%)': '6.0', 'Precision_Difference(%)': '2.0', 'Elapsed_Time(Sec.)': '10.87'}, {'max_words': 800, 'Precision[Training](%)': '95.0', 'F1-Score[Training](%)': '95.0', 'Recall[Training](%)': '95.0', 'Mean Absolute Error[Training](%)': '8.0', 'Precision[Test](%)': '95.0', 'F1-Score[Test](%)': '95.0', 'Recall[Test](%)': '95.0', 'Mean Absolute Error[Test](%)': '8.0', 'Precision_Difference(%)': '-0.0', 'Elapsed_Time(Sec.)': '10.54'}, {'max_words': 850, 'Precision[Training](%)': '48.0', 'F1-Score[Training](%)': '48.0', 'Recall[Training](%)': '48.0', 'Mean Absolute Error[Training](%)': '52.0', 'Precision[Test](%)': '51.0', 'F1-Score[Test](%)': '51.0', 'Recall[Test](%)': '51.0', 'Mean Absolute Error[Test](%)': '49.0', 'Precision_Difference(%)': '-3.0', 'Elapsed_Time(Sec.)': '5.42'}, {'max_words': 900, 'Precision[Training](%)': '96.0', 'F1-Score[Training](%)': '96.0', 'Recall[Training](%)': '96.0', 'Mean Absolute Error[Training](%)': '6.0', 'Precision[Test](%)': '96.0', 'F1-Score[Test](%)': '96.0', 'Recall[Test](%)': '96.0', 'Mean Absolute Error[Test](%)': '6.0', 'Precision_Difference(%)': '-0.0', 'Elapsed_Time(Sec.)': '10.8'}, {'max_words': 950, 'Precision[Training](%)': '96.0', 'F1-Score[Training](%)': '96.0', 'Recall[Training](%)': '96.0', 'Mean Absolute Error[Training](%)': '5.0', 'Precision[Test](%)': '95.0', 'F1-Score[Test](%)': '95.0', 'Recall[Test](%)': '95.0', 'Mean Absolute Error[Test](%)': '6.0', 'Precision_Difference(%)': '1.0', 'Elapsed_Time(Sec.)': '11.33'}, {'max_words': 1000, 'Precision[Training](%)': '91.0', 'F1-Score[Training](%)': '91.0', 'Recall[Training](%)': '91.0', 'Mean Absolute Error[Training](%)': '16.0', 'Precision[Test](%)': '91.0', 'F1-Score[Test](%)': '91.0', 'Recall[Test](%)': '91.0', 'Mean Absolute Error[Test](%)': '16.0', 'Precision_Difference(%)': '1.0', 'Elapsed_Time(Sec.)': '7.49'}, {'max_words': 1050, 'Precision[Training](%)': '96.0', 'F1-Score[Training](%)': '96.0', 'Recall[Training](%)': '96.0', 'Mean Absolute Error[Training](%)': '5.0', 'Precision[Test](%)': '95.0', 'F1-Score[Test](%)': '95.0', 'Recall[Test](%)': '95.0', 'Mean Absolute Error[Test](%)': '6.0', 'Precision_Difference(%)': '1.0', 'Elapsed_Time(Sec.)': '11.32'}, {'max_words': 1100, 'Precision[Training](%)': '95.0', 'F1-Score[Training](%)': '95.0', 'Recall[Training](%)': '95.0', 'Mean Absolute Error[Training](%)': '8.0', 'Precision[Test](%)': '95.0', 'F1-Score[Test](%)': '95.0', 'Recall[Test](%)': '95.0', 'Mean Absolute Error[Test](%)': '8.0', 'Precision_Difference(%)': '-0.0', 'Elapsed_Time(Sec.)': '10.23'}, {'max_words': 1150, 'Precision[Training](%)': '91.0', 'F1-Score[Training](%)': '91.0', 'Recall[Training](%)': '91.0', 'Mean Absolute Error[Training](%)': '17.0', 'Precision[Test](%)': '91.0', 'F1-Score[Test](%)': '91.0', 'Recall[Test](%)': '91.0', 'Mean Absolute Error[Test](%)': '17.0', 'Precision_Difference(%)': '-0.0', 'Elapsed_Time(Sec.)': '7.91'}, {'max_words': 1200, 'Precision[Training](%)': '76.0', 'F1-Score[Training](%)': '76.0', 'Recall[Training](%)': '76.0', 'Mean Absolute Error[Training](%)': '26.0', 'Precision[Test](%)': '76.0', 'F1-Score[Test](%)': '76.0', 'Recall[Test](%)': '76.0', 'Mean Absolute Error[Test](%)': '26.0', 'Precision_Difference(%)': '0.0', 'Elapsed_Time(Sec.)': '6.77'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        },
        "id": "0aIuVxPGxt86",
        "outputId": "91630f7d-6523-4ddb-bec9-feabafcd95b3"
      },
      "source": [
        "df = pd.DataFrame(bench_mark_results)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>max_words</th>\n",
              "      <th>Precision[Training](%)</th>\n",
              "      <th>F1-Score[Training](%)</th>\n",
              "      <th>Recall[Training](%)</th>\n",
              "      <th>Mean Absolute Error[Training](%)</th>\n",
              "      <th>Precision[Test](%)</th>\n",
              "      <th>F1-Score[Test](%)</th>\n",
              "      <th>Recall[Test](%)</th>\n",
              "      <th>Mean Absolute Error[Test](%)</th>\n",
              "      <th>Precision_Difference(%)</th>\n",
              "      <th>Elapsed_Time(Sec.)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50</td>\n",
              "      <td>86.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>14.000000000000002</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>8.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>7.000000000000001</td>\n",
              "      <td>94.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>150</td>\n",
              "      <td>92.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>7.000000000000001</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>9.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>200</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>250</td>\n",
              "      <td>48.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>5.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>300</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>350</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>7.000000000000001</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>9.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>400</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>7.000000000000001</td>\n",
              "      <td>94.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>7.000000000000001</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>10.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>450</td>\n",
              "      <td>96.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>500</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>14.000000000000002</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>14.000000000000002</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>550</td>\n",
              "      <td>48.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>5.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>600</td>\n",
              "      <td>48.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>5.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>650</td>\n",
              "      <td>96.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>700</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>9.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>750</td>\n",
              "      <td>96.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>800</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>10.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>850</td>\n",
              "      <td>48.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>5.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>900</td>\n",
              "      <td>96.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>10.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>950</td>\n",
              "      <td>96.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1000</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1050</td>\n",
              "      <td>96.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1100</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>10.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1150</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>7.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1200</td>\n",
              "      <td>76.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.77</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    max_words Precision[Training](%)  ... Precision_Difference(%) Elapsed_Time(Sec.)\n",
              "0          50                   86.0  ...                    -4.0               8.68\n",
              "1         100                   95.0  ...                     1.0              10.67\n",
              "2         150                   92.0  ...                    -2.0               9.72\n",
              "3         200                   95.0  ...                     1.0              10.57\n",
              "4         250                   48.0  ...                    -3.0               5.71\n",
              "5         300                   93.0  ...                     0.0               8.64\n",
              "6         350                   93.0  ...                    -0.0               9.74\n",
              "7         400                   93.0  ...                    -1.0              10.56\n",
              "8         450                   96.0  ...                     1.0              11.01\n",
              "9         500                   91.0  ...                     1.0                8.0\n",
              "10        550                   48.0  ...                    -3.0               5.26\n",
              "11        600                   48.0  ...                    -3.0               5.76\n",
              "12        650                   96.0  ...                     1.0              10.76\n",
              "13        700                   93.0  ...                    -1.0               9.32\n",
              "14        750                   96.0  ...                     2.0              10.87\n",
              "15        800                   95.0  ...                    -0.0              10.54\n",
              "16        850                   48.0  ...                    -3.0               5.42\n",
              "17        900                   96.0  ...                    -0.0               10.8\n",
              "18        950                   96.0  ...                     1.0              11.33\n",
              "19       1000                   91.0  ...                     1.0               7.49\n",
              "20       1050                   96.0  ...                     1.0              11.32\n",
              "21       1100                   95.0  ...                    -0.0              10.23\n",
              "22       1150                   91.0  ...                    -0.0               7.91\n",
              "23       1200                   76.0  ...                     0.0               6.77\n",
              "\n",
              "[24 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvp6TSXSTgg8"
      },
      "source": [
        "tf_idf=TfidfVectorizer(sublinear_tf=True,min_df=3,norm='l2',encoding='utf-8',ngram_range=(1,3))\n",
        "train_featurs=tf_idf.fit_transform(X_train)\n",
        "test_featurs=tf_idf.transform(X_test)\n",
        "train_labls=Y_train\n",
        "test_labls=Y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVHXwhtuTkXw"
      },
      "source": [
        "# Create classifiers\n",
        "dt=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
        "                                            max_depth=3, max_features=None, max_leaf_nodes=None,\n",
        "                                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                                            min_samples_leaf=1, min_samples_split=10,\n",
        "                                            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
        "                                            splitter='best')\n",
        "\n",
        "rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
        "                                            max_depth=3, max_features='sqrt', max_leaf_nodes=None,\n",
        "                                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                                            min_samples_leaf=1, min_samples_split=2,\n",
        "                                            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
        "                                            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
        "\n",
        "ad=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
        "                                      learning_rate=0.05, n_estimators=16, random_state=None)\n",
        "\n",
        "lg=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "                                      intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
        "                                      n_jobs=1, penalty='l1', random_state=0, solver='saga',\n",
        "                                      tol=0.0001, verbose=0, warm_start=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS66ZzBGToc5"
      },
      "source": [
        "seed = 1075\n",
        "no_Of_Folds=10\n",
        "accuracy_scores=[]\n",
        "\n",
        "eclf=VotingClassifier(estimators=[('dt', dt), ('rf', rf), ('ad', ad),('lg',lg)], voting='soft')\n",
        "bagging_clf = BaggingClassifier(eclf, max_samples=0.4, max_features=10, random_state=seed)\n",
        "bagging_clf.fit(train_featurs,train_labls)  \n",
        "eclf.fit(train_featurs,train_labls)  \n",
        "\n",
        "\n",
        "#Train data set with bagging\n",
        "yPredicted_train_bag = bagging_clf.predict(train_featurs)\n",
        "precision_train_bag,recall_train_bag,fscore_train_bag,support_train_bag=score(train_labls,yPredicted_train_bag,average='macro')\n",
        " \n",
        "\n",
        "#Test data set with bagging\n",
        "yPredicted_test_bag = bagging_clf.predict(test_featurs)\n",
        "precision_test_bag,recall_test_bag,fscore_test_bag,support_test_bag=score(test_labls,yPredicted_test_bag,average='macro')\n",
        "\n",
        "\n",
        "#Train data set without bagging\n",
        "yPredicted_train_without_bag = eclf.predict(train_featurs)\n",
        "precision_train_without_bag,recall_train_without_bag,fscore_train_without_bag,support_train_without_bag=score(train_labls,yPredicted_train_without_bag,average='macro')\n",
        "cross_val_score_train_without_bag=cross_val_score(eclf, train_featurs , train_labls, cv=no_Of_Folds) \n",
        "\n",
        "#Test data set without bagging\n",
        "yPredicted_test_without_bag = eclf.predict(test_featurs)\n",
        "precision_test_without_bag,recall_test_without_bag,fscore_test_without_bag,support_test_without_bag=score(test_labls,yPredicted_test_without_bag,average='macro')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_SILmNjTzRS",
        "outputId": "b7c633e6-d624-4989-d401-8712c9c93f82"
      },
      "source": [
        "accuracy_scores.append({\n",
        "                                    'Is Bagging Used':'YES',\n",
        "                                     'Precision[Training](%)':str(round(precision_train_bag,2)*100),                                     \n",
        "                                     'Precision[Test](%)':str(round(precision_test_bag,2)*100),                                    \n",
        "                                     'Precision_Difference(%)':str((round((round(precision_train_bag,2)-round(precision_test_bag,2)),2)*100)),\n",
        "                                     'Mean Absolute Error[Training](%)':Get_Absolute_Mean_Error(train_labls,yPredicted_train_bag),\n",
        "                                     'Mean Absolute Error[Test](%)':Get_Absolute_Mean_Error(test_labls,yPredicted_test_bag),\n",
        "                                     'F1-Score[Train](%)':str(round(fscore_train_bag,2)*100),\n",
        "                                     'F1-Score[Test](%)':str(round(fscore_test_bag,2)*100),\n",
        "                                     'Recall[Train](%)':str(round(recall_train_bag,2)*100),\n",
        "                                     'Recall[Test](%)':str(round(recall_test_bag,2)*100),\n",
        "                                     #'CV Score[Train](%)':str(round(cross_val_score_train_bag.mean(),2)*100),\n",
        "                                     #'CV Score[Test](%)':str(round(cross_val_score_test_bag.mean(),2)*100)\n",
        "    \n",
        "    \n",
        "                                   })\n",
        "\n",
        "accuracy_scores.append({             \n",
        "                                     'Is Bagging Used':'NO',\n",
        "                                     'Precision[Training](%)':str(round(precision_train_without_bag,2)*100),                                     \n",
        "                                     'Precision[Test](%)':str(round(precision_test_without_bag,2)*100),                                    \n",
        "                                     'Precision_Difference(%)':str((round((round(precision_train_without_bag,2)-round(precision_test_without_bag,2)),2)*100)),\n",
        "                                     'Mean Absolute Error[Training](%)':Get_Absolute_Mean_Error(train_labls,yPredicted_train_without_bag),\n",
        "                                     'Mean Absolute Error[Test](%)':Get_Absolute_Mean_Error(test_labls,yPredicted_test_without_bag),\n",
        "                                     'F1-Score[Train](%)':str(round(fscore_train_without_bag,2)*100),\n",
        "                                     'F1-Score[Test](%)':str(round(fscore_test_without_bag,2)*100),\n",
        "                                     'Recall[Train](%)':str(round(recall_train_without_bag,2)*100),\n",
        "                                     'Recall[Test](%)':str(round(recall_test_without_bag,2)*100),                              \n",
        "    \n",
        "                                   })\n",
        "\n",
        "print(accuracy_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'Is Bagging Used': 'YES', 'Precision[Training](%)': '82.0', 'Precision[Test](%)': '80.0', 'Precision_Difference(%)': '2.0', 'Mean Absolute Error[Training](%)': 23.59, 'Mean Absolute Error[Test](%)': 25.62, 'F1-Score[Train](%)': '76.0', 'F1-Score[Test](%)': '73.0', 'Recall[Train](%)': '77.0', 'Recall[Test](%)': '74.0'}, {'Is Bagging Used': 'NO', 'Precision[Training](%)': '91.0', 'Precision[Test](%)': '89.0', 'Precision_Difference(%)': '2.0', 'Mean Absolute Error[Training](%)': 10.16, 'Mean Absolute Error[Test](%)': 13.12, 'F1-Score[Train](%)': '90.0', 'F1-Score[Test](%)': '87.0', 'Recall[Train](%)': '90.0', 'Recall[Test](%)': '87.0'}, {'Is Bagging Used': 'YES', 'Precision[Training](%)': '82.0', 'Precision[Test](%)': '80.0', 'Precision_Difference(%)': '2.0', 'Mean Absolute Error[Training](%)': 23.59, 'Mean Absolute Error[Test](%)': 25.62, 'F1-Score[Train](%)': '76.0', 'F1-Score[Test](%)': '73.0', 'Recall[Train](%)': '77.0', 'Recall[Test](%)': '74.0'}, {'Is Bagging Used': 'NO', 'Precision[Training](%)': '91.0', 'Precision[Test](%)': '89.0', 'Precision_Difference(%)': '2.0', 'Mean Absolute Error[Training](%)': 10.16, 'Mean Absolute Error[Test](%)': 13.12, 'F1-Score[Train](%)': '90.0', 'F1-Score[Test](%)': '87.0', 'Recall[Train](%)': '90.0', 'Recall[Test](%)': '87.0'}, {'Is Bagging Used': 'YES', 'Precision[Training](%)': '82.0', 'Precision[Test](%)': '80.0', 'Precision_Difference(%)': '2.0', 'Mean Absolute Error[Training](%)': 23.59, 'Mean Absolute Error[Test](%)': 25.62, 'F1-Score[Train](%)': '76.0', 'F1-Score[Test](%)': '73.0', 'Recall[Train](%)': '77.0', 'Recall[Test](%)': '74.0'}, {'Is Bagging Used': 'NO', 'Precision[Training](%)': '91.0', 'Precision[Test](%)': '89.0', 'Precision_Difference(%)': '2.0', 'Mean Absolute Error[Training](%)': 10.16, 'Mean Absolute Error[Test](%)': 13.12, 'F1-Score[Train](%)': '90.0', 'F1-Score[Test](%)': '87.0', 'Recall[Train](%)': '90.0', 'Recall[Test](%)': '87.0'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "BKM4bILvJumO",
        "outputId": "f70696a4-e71b-4c94-e10f-74137e036a6c"
      },
      "source": [
        "df = pd.DataFrame(accuracy_scores)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Is Bagging Used</th>\n",
              "      <th>Precision[Training](%)</th>\n",
              "      <th>Precision[Test](%)</th>\n",
              "      <th>Precision_Difference(%)</th>\n",
              "      <th>Mean Absolute Error[Training](%)</th>\n",
              "      <th>Mean Absolute Error[Test](%)</th>\n",
              "      <th>F1-Score[Train](%)</th>\n",
              "      <th>F1-Score[Test](%)</th>\n",
              "      <th>Recall[Train](%)</th>\n",
              "      <th>Recall[Test](%)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>YES</td>\n",
              "      <td>82.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>23.59</td>\n",
              "      <td>25.62</td>\n",
              "      <td>76.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>74.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NO</td>\n",
              "      <td>91.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.16</td>\n",
              "      <td>13.12</td>\n",
              "      <td>90.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>87.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>YES</td>\n",
              "      <td>82.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>23.59</td>\n",
              "      <td>25.62</td>\n",
              "      <td>76.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>74.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NO</td>\n",
              "      <td>91.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.16</td>\n",
              "      <td>13.12</td>\n",
              "      <td>90.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>87.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>YES</td>\n",
              "      <td>82.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>23.59</td>\n",
              "      <td>25.62</td>\n",
              "      <td>76.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>74.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NO</td>\n",
              "      <td>91.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.16</td>\n",
              "      <td>13.12</td>\n",
              "      <td>90.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>87.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Is Bagging Used Precision[Training](%)  ... Recall[Train](%) Recall[Test](%)\n",
              "0             YES                   82.0  ...             77.0            74.0\n",
              "1              NO                   91.0  ...             90.0            87.0\n",
              "2             YES                   82.0  ...             77.0            74.0\n",
              "3              NO                   91.0  ...             90.0            87.0\n",
              "4             YES                   82.0  ...             77.0            74.0\n",
              "5              NO                   91.0  ...             90.0            87.0\n",
              "\n",
              "[6 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}